<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>El análisis del español mediante los corpus</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Chad Howe, Ph.D.</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="students.html">Students</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://twitter.com/ChoweAthens">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/ChadHoweUGA">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://www.researchgate.net/profile/Chad_Howe2">RG</a>
</li>
<li>
  <a href="https://orcid.org/0000-0002-3044-1443">ORCiD</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">El análisis del español mediante los corpus</h1>

</div>


<div id="introducción" class="section level1">
<h1>Introducción</h1>
<p><strong>Descripción del curso:</strong></p>
<p>En este curso, utilizaremos los corpus para explorar cuestiones lingüísticas del español. Además, desarrollaremos un conocimiento más amplio del campo de la Lingüística de Corpus (LC), tanto como una perspectiva metodológica como una sub-disciplina dentro de las ciencias de la lengua. Los estudiantes aprenderán una variedad de técnicas para el estudio de los corpus, entre ellos el uso del UGA Corpus Server y el CQP Query Language. Las áreas de estudio incluirán (i) diferentes aspectos del análisis lingüístico (p.e. la semántica léxica, las colocaciones, la adquisición, y la variación gramatical) y (ii) algunas perspectivas del campo de las humanidades digitales sobre los textos electrónicos como la codificación, la manipulación de archivos, y (tal vez) la estilística. Los estudiantes tendrán que realizar proyectos de investigación originales en los cuales se integran las diferentes perspectivas y metodologías presentadas en clase. Los temas comparativos (p.e. el español y el portugués) también son bienvenidos.</p>
<hr />
</div>
<div id="introduccion" class="section level1">
<h1>1a Semana</h1>
<div id="qué-es-un-corpus" class="section level2 unnumbered">
<h2>¿Qué es un corpus?</h2>
<p>En esta clase se introducirá el uso de los corpus para el análisis del español (y otras lenguas). Nuestra primera cuestión se contestará así</p>
<blockquote>
<p>El análisis de corpus es el uso de métodos, normalmente computacionales, de colecciones de lengua humana con el fin de sacar conclusiones sobre el lenguaje o alguna característica de los usuarios del lenguaje (p.e. el/la autor(a), grupos demográficos, etc.).</p>
</blockquote>
<p>Para este primer día de clase, hableremos de uso del <strong>UGA corpus server</strong>. El programa que utilizaremos hoy para explorar esta colección de corpus se llama <a href="http://cwb.sourceforge.net/documentation.php">el Corpus Query Processor (CQP)</a>. El CQP te ofrece ciertas herramientas que facilitan el proceso de trabajar con datos electrónicos. Se introducirán otras técnicas durante el curso, pero es sumamente importante que tengamos una base sólida del CQP para poder seguir con los temas del curso. Por favor, consulta los mandatos del CQP descritos en el Manual. Entiendo que el uso del CQP puede ser intimidante, pero espero poder guiaros paso a paso.</p>
<hr />
</div>
<div id="el-uso-del-servidor" class="section level2 unnumbered">
<h2>El uso del servidor</h2>
<p>Para poder utilizar CQP, tenemos que empezar con un programa que nos permite acceso al server:</p>
<ol style="list-style-type: decimal">
<li>Hay que conectar directamente al UGA campus network o al <a href="https://uga.view.usg.edu/d2l/le/content/2064782/viewContent/31621926/View">Virtual Private Network</a>.</li>
<li>Hay que tener una cuenta para el servir. Ya os he creado cuentas para todos. Estas cuentas requieren tu <strong>UGA myID</strong> y tu contraseña.</li>
</ol>
<p>El server existe como parte del sistema operador de linus. Se puede convertir temporalmente la computadora donde trabajas en <a href="https://uga.view.usg.edu/d2l/le/content/2064782/viewContent/31621926/ViewEte">un terminal</a> para el server mediante el uso del mandato <code>ssh</code>. Las instrucciones presentadas en el documento que se llama “Utilizing the UGA Corpus Server” describen este proceso.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Para esta fase del curso, trabajaremos con dos programas que facilitan el proceso de acceder al servidor: <strong>Terminal</strong> (macOS) o <a href="https://uga.view.usg.edu/d2l/le/content/2064782/viewContent/31621926/View">Putty</a> (Windows).</p>
<p>El primero paso al abrir el programa relevante (es decir, Terminal o Putty) será hacer el login con tu UGA myID. Una vez que se haya conectado al server, hay que iniciar CQP desde el mensaje (‘prompt’) de linux, con el uso de las etiquetas <code>e</code> y <code>c</code>:<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<ul>
<li><code>kucera $ cqp -eC</code></li>
</ul>
<p>La etiqueta <code>-e</code> te ofrece opciones limitadas para revisar líneas del código, como el acceso a mandotos previous con el <code>up-arrow key'. La etiqueta</code>-C’ produce los colores que observas. Al comenzar, el mensaje de linux (<code>$</code>) se reemplaza con el mensaje del CQP, lo cual es <code>[no corpus]</code> en el estado inicial. Puedes pedir que te muestre la lista de los corpus disponibles así. Notad que todos los mandatos del CQP se debe finalizar con el punto y coma.</p>
<ul>
<li><code>[no corpus]&gt; show corpora;</code></li>
</ul>
<div class="figure">
<img src="images/CQPImage1.png" alt="" />
<p class="caption">Colección de corpora</p>
</div>
<p>No todos los corpus que existen como parte de <a href="http://research.franklin.uga.edu/linglab/corpora">la colección del Departamento de Lingüística de UGA</a> son accesibles mediante CQP. Para averiguar más sobre un corpus partícular, utiliza el mandato <code>info</code>. Puedes salir de CQP con el mandato <code>exit</code>; otro uso de <code>exit</code> o <code>logout</code> te quitará del servidor.</p>
<div class="figure">
<img src="images/CQPImage2.png" alt="" />
<p class="caption">Selección de corpus</p>
</div>
<center>
<a href="#introduccion">Arriba</a>
</center>
<hr />
</div>
</div>
<div id="a-semana" class="section level1">
<h1>2a Semana</h1>
<div id="nuestra-primera-consulta" class="section level2 unnumbered">
<h2>Nuestra primera consulta</h2>
<p>Las consultas más simples son palabras simples. Si se busca una palabra entre comillas (""), lo que se produce es una <strong>concordancia</strong> del tipo KWIC (‘Key Words in Context’) <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node9.html">CQP, sección 2.3</a>.</p>
<ul>
<li><code>WUTHERING&gt; "hardly" ;</code></li>
</ul>
<p>Para navegar los resultados, hay que utilizar el <em>spacebar</em> (lo cual avanza los resultados página por página), el <em>returEn key</em> (línea por línea), o <code>q</code> para terminar la búsqueda. En la visualización de KWIC, la palabra que concuerda con tu consulta se identifica con corchetes ángulares. Los números a la izquierda representan posiciones en el corpus. Estos números se pueden suprimir con el siguiente mandato:</p>
<ul>
<li><code>WUTHERING&gt; show -cpos ;</code></li>
</ul>
<p>Hay otras opciones que se pueden modificar. Por ejemplo, el mandato <code>+cpos</code> restaura los números para las próximas consultas. También, puedes pedir que CQP te produzca una cabecera para cada concordancia (CQP, sección 2.4). Para terminar con esta opción, hay que hacer el siguiente:</p>
<ul>
<li><code>WUTHERING&gt; show PrintOptions hdr;</code></li>
<li><code>WUTHERING&gt; show PrintOptions nohdr;</code></li>
</ul>
</div>
<div id="contar-los-ejemplos" class="section level2">
<h2>Contar los ejemplos</h2>
<p>El CQP te puede contar los ejemplos de una palabra, pero es importante considerar lo significan estos números. Consideremos nuestra consulta de “hardly” con el corpus de WUTHERING. Se puede pedir que el CQP te cuente el número de ejemplos de la última consulta con el mandato <code>count</code> (CQP, sección 2.9).</p>
<ul>
<li><code>WUTHERING&gt; "hardly";</code></li>
<li><code>WUTHERING&gt; count by word;</code> <code>43       hardly     [#0-#42]</code></li>
</ul>
<p>El número que se encuentra a la izquierda es el número total de atestaciones de “hardly” en la novela <em>Wuthering Heights</em>–es decir, 43. Si comparamos este número con otra colección del siglo 19 (Charles Dickens, CQP sección 1.3), conseguimos los siguientes resultados:</p>
<ul>
<li><code>WUTHERING&gt; DICKENS;</code></li>
<li><code>DICKENS&gt; "hardly";</code></li>
<li><code>DICKENS&gt; count by word;</code> <code>451       hardly     [#0-#450]</code></li>
</ul>
<p>Con estos resultados, ¿debemos concluir que el uso de “hardly” es mayor en Dickens que el trabajo de Brontë? La respuesta es que NO. Si consultamos la información de estos dos corpus (con el mandato <code>info</code>), veremos que el tamaño (indicado en la sección de <code>size</code>) del corpus de DICKENS es mucho mayor (3.4 millones de casos de varios libros) que el de <em>Wuthering Heights</em>, con su 1.400 casos. Entonces, lo que tenemos que hacer es <em>relativizar</em> las frecuencias. Veremos esto más adelante.</p>
</div>
<div id="los-casos-tokens" class="section level2">
<h2>Los casos (‘tokens’)</h2>
<p>Los corpora son divididos en casos (‘tokens’) discretos. Un casos es simplemente un elemento que ocupa una posición específica. Típicamente, un caso es una palabra (sobre todo con los corpus canónicos), pero hay casos no tan claros. Por ejemplo, con el corpus de <em>Wuthering Heights</em>, la ‘s’ con el apóstrofe también es un caso.</p>
<ul>
<li><code>WUTHERING&gt; "'s'";</code></li>
</ul>
<p>Las consultas con CQP son especificaciones de propiedades que deben de tener casos particulares. Por ejemplo, cuando escribimos la palabra “hardly” entre comillas, pedimos que CQP nos encuentre un caso que se escribe ‘h-a-r-d-l-y’. Dicho de otra forma, pedimos que nos de un caso donde el atributo <code>word</code> tiene con su valor la serie ‘h-a-r-d-l-y’. Encontonces, consulta que realizamos anteriomente es igual al siguiente:</p>
<ul>
<li><code>WUTHERING&gt; [ word="hardly" ] ;</code></li>
</ul>
<p>Toda expresión que se escriba entre corchetes (“[…]”) describe un caso simple. Este método de realizar una consulta señala al CQP que lo que importa para esta consulta es la ortografía de la palabra. Sin embargo, los casos pueden tener otro atributos y podemos realizar una consulta con más de un conjunto de corchetes. La siguiente consulta encuentra casos de “hardly know” y “hardly knew” ya que las dos formas de la segunda forma comparten el mismo <strong>lema</strong>.</p>
<ul>
<li><code>WUTHERING&gt; [ word="hardly" ] [ lemma="know" ] ;</code></li>
</ul>
<p><strong>Los lemas</strong> están disponibles como atributo adicional en algunos de los corpus que se encuentran en el servidor. Nos facilita el proceso de buscar casos sin preocuparnos de formas variantes morfológicas.</p>
<p>Si no imponenos ninguna restricción y dejamos que los corchetes estén vacíos, el CQP nos encuentra todos los casos que concuerden con estas posiciones. Así que, ¿cuáles son las palabras que co-ocurren con “hardly”?</p>
<ul>
<li><code>WUTHERING&gt; [ ] [ lemma="know" ] ;</code></li>
<li><code>WUTHERING&gt; count by word ;</code></li>
</ul>
<p>Para especificar la consulta, podemos añadir el elemento <code>cut</code> que requiere que no se imprima las concordancias con menos de un número específico de casos.</p>
<ul>
<li><code>WUTHERING&gt; count by word cut 2 ;</code></li>
</ul>
<p>Con los resultados del mandato <code>count</code>, se nota que el número a la izquierda representa el número total de casos de secuencias de dos palabras que aparecen con “hardly” en <em>Wuthering Heights</em>. Se nota que el grupo más frecuente es la secuencia “I hardly”, seguida de grupos con los verbos modales <em>can</em> y <em>could</em>. Ahora, inténtalo con el corpus de Dickens.</p>
<p>¿y qué pasa con un corpus mucho más grande como el NYT (1.35 mil millones de palabras)?</p>
<div class="figure">
<img src="images/CQPHardlyNYT.png" alt="" />
<p class="caption">Secuencias con ‘hardly’ en el NYT</p>
</div>
<p>En el estilo del periodisimo representando por el corpus del NYT, se observa que las combinaciones con los verbos copulativos y los verbos modales son las secuencias más frecuentes, mientras que la secuencia de “I hardly” no es tan prominente. Lo que nos muestran estos resultados es que los corpus nos ofrecen una forma de observar <strong>el uso lingüístico</strong>. Es obvio pero importante destacar que el análsis lingüístico mediante corpus depende de los corpus, que son <strong>muestras de una lengua</strong>. Estas muestras son ejemplos de registros, estilos y contextos específicos. Si replicamos la misma consulta con el Spoken British National Corpus del año 2014, vemos de nuevo que la secuenca “I hardly” es algo frecuente. El texto de los periódicos, la producción literaria y el habla son todos registros distintos.</p>
<div class="figure">
<img src="images/CQPBNChardly.png" alt="" />
<p class="caption">Secuencias con ‘hardly’ en el Spoken BNC 2014</p>
</div>
<p><strong>Pregunta</strong>: Con el uso del corpus ANCORA, contesta las siguientes preguntas:</p>
<ol style="list-style-type: decimal">
<li>¿Cuántos casos hay de la palabra <em>todo</em> en el corpus?</li>
<li>¿Cuáles son las formas de la palabra <em>todo</em> en el corpus?</li>
<li>¿Cuántos casos hay de cada uno de estas formas?</li>
<li>¿Cuáles son las palabras que ocurren antes de la palabra <em>todos</em>? Y después?</li>
</ol>
</div>
<div id="las-distribuciones" class="section level2">
<h2>Las distribuciones</h2>
<p>En el análsis de corpus, a veces queremos ignorar variaciones que ocurren como función de, por ejemplo, la ortografía. Si utilizamos el corpus BNC-BABY (una muestra limitada del BNC), podemos ignorar la diferencias entre letras mayúsculas y minúsculas con la etiqueta <code>%c</code>.</p>
<ul>
<li><code>BNC-BABY&gt; [ word="bank"];</code></li>
<li><code>BNC-BABY&gt; [ word="bank" %c];</code></li>
</ul>
<p>También, podemos buscar por lemas; es decir, variantes morfológicas de una palabra:</p>
<ul>
<li><code>DICKENS&gt; [ lemma="go" ] ;</code></li>
</ul>
<p>Los elementos <code>word</code> y <code>lemma</code> son atributos posicionales; es decir, son definidos para cada caso para toda posición en el corpus. Los otros atributos posicionales se pueden averiguar con el corpus actual/activo mediante el mandato <code>show cd</code>.</p>
<div id="consultas-con-nombre" class="section level3">
<h3>Consultas con nombre</h3>
<p>Las consultas se pueden nombrar:</p>
<ul>
<li><code>ANCORA&gt; Ahora = "ahora";</code></li>
</ul>
<p>Nótete que no se produce un resultado. Sin embargo, podemos utilizar el output de esto proceso para ver, por ejemplo, la concordancia. Por ejemplo, con el mandato <code>cat</code>, podemos pedir que nos muestre la concordancia. También, podemos encontrar el número de casos con el mandato <code>size</code> (CQP, sección 3.1).</p>
<ul>
<li><code>ANCORA&gt; cat Ahora;</code></li>
<li><code>ANCORA &gt; size Ahora;</code></li>
</ul>
<p>De hecho, todas las consultas reciben, por defeto, el nombre <code>Last</code>. Si realizas una consulta sin especificar un nombre, puedes asignar un nombre con el “=”.</p>
<ul>
<li><code>ANCORA&gt; "desde" ;</code></li>
<li><code>ANCORA&gt; d = Last ;</code></li>
<li><code>ANCORA&gt; "entonces" ;</code></li>
<li><code>ANCORA&gt; show named;</code></li>
</ul>
<p>El mandato <code>show named</code> produce una lista de todas las consultas que se han hecho durante la sesión actual, entre ellas los que tienen el nombre implícito de <code>Last</code>. Estas consultas se guardan en la memoria (m) y desaparecen cuando terminas las sesión, o si pides que las discartes.</p>
</div>
<div id="el-mandato-group" class="section level3">
<h3>El mandato <code>group</code></h3>
<p>El mandato <code>group</code> es similar a otros mandatos de CQP como <code>cat</code>, <code>sort</code>, <code>count</code>, y <code>size</code> en que requiere el nombre de una consulta como un argumento. En el siguiente ejemplo, la consulta tiene el nombre K. Luego, aplicamos el mandato <code>group</code> a la consulta K y pedimos que nos muestre la distribución de frecuencias de las palabras que concuerden con la consulta:</p>
<div class="figure">
<img src="images/CQPKnock.png" alt="" />
<p class="caption">El uso del mandato group</p>
</div>
<p>El mismo grupo de mandatos también se pueden aplicar a las consultas de casos múltiples. Pregunta: ¿Cuánto son los casos de combinaciones de dos palabras como “knock out”?</p>
<div class="figure">
<img src="images/CQPKnock2.png" alt="" />
<p class="caption">Casos de “knock out”</p>
</div>
<p>Ahora podemos aplicar el mandato <code>group</code> a esta consulta también. Solo tiene que especificar cuál es el grupo que queremos. En esta situación, queremos la primera palabra a la derecha del elemento que buscamos, de acuerdo con su atributo de <code>word</code>.</p>
<div class="figure">
<img src="images/CQPKnock3.png" alt="" />
<p class="caption">Casos de “knock out”</p>
</div>
<p>Según estos resultados, los casos de “knock out” son menos frequentes que los casos de “knock on”. Con el uso de la palabra clave <code>by</code>, podemos crear una tabla de dos dimensiones para considerar detalladamente esta distribución. En este caso, <code>hw</code> significa ‘headword’, lo cual representa el atributo del BNC que identifica la raíz morfológica (similar a <code>lemma</code>).</p>
<div class="figure">
<img src="images/CQPKnock4.png" alt="" />
<p class="caption">Casos de “knock out”</p>
</div>
<p>Estos números en la columna a la derecha del output de <code>group</code> representan una distribución de frecuencia. Son una medida cuantitativa que describe la frecuencia de de una forma partícular.</p>
</div>
</div>
<div id="los-metadatos-metadata" class="section level2">
<h2>Los metadatos (‘metadata’)</h2>
<p>El término ‘metadata’ se refiere a esta información que describe los diferentes aspectos (sociales, dialectales, entre muchos otros) del corpus. Por ejemplo, abajo se presentan algunos de los atributos disponibles con el BNC:</p>
<p><img src="images/BNCAttributes.png" alt="Structural Attributes for the BNC" /> Podemos utilizar estos atributos para realizar una consulta más precisa:</p>
<ul>
<li><code>BNC-BABY&gt;[word="fantastic"]::match.text_mode="spoken" &amp; match.u_sex="female";</code></li>
</ul>
<p>Con esta consulta, estamos buscando la palabra ‘fantastic’, pero hemos especificado que queremos de los casos (i) de la porción oral del corpus (<code>match-text_mode="spoken"</code>) y (ii) producidos por las personas indicadas como mujeres (<code>match.u_sex="female"</code>). Estos atributos se describen como <em>s-attributes</em> (donde la <em>s</em> = ‘estructura’). El corpus de EUROPARL-ES, por ejemplo, contiene los siguientes s-attributes:</p>
<p><img src="images/EUROPARL-ESAttributes.png" alt="Structural Attributes for the BNC" /> Se puede encontrar más información sobre estos atributos en <a href="http://www.statmt.org/europarl/">la documentación sobre el corpus</a>. Como un ejemplo, el atributo <code>speaker_language</code> indica la lengua original del hablante que produjo el caso.</p>
<p>Para ver un ejemplo tal vez más concreto, consideremos el corpus BNC-BABY, un sub-corpus del BNC. Con la siguiente consulta, utilizamos el mandato <code>match</code> para pedir los casos de la palabra ‘lovely’ según el sexo del/de la autor(a):</p>
<ul>
<li><code>BNC-BABY&gt; L = "lovely";</code></li>
<li><code>BNC-BABY&gt; group L match text_author_sex ;</code></li>
</ul>
<div class="figure">
<img src="images/BNCLovely.png" alt="" />
<p class="caption">Casos de “lovely” en el BNC según sexo</p>
</div>
<p>Podemos también utilizar el elemento <code>::</code> para indicar un ‘global constraint’ (manual de CQP, sección 4.1). En la siguiente consulta, definimos un elemento (‘M’) que contiene los casos de la palabra “mate”. Además, especificamos (con el <code>::</code>) que no queremos casos que tengan el valor “unknown”.</p>
<div class="figure">
<img src="images/BNCMate.png" alt="" />
<p class="caption">Casos de “mate” en el BNC según edad</p>
</div>
<hr />
</div>
</div>
<div id="a-semana-1" class="section level1">
<h1>3a Semana</h1>
<div id="los-verbos-modales" class="section level2">
<h2>Los verbos modales<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></h2>
<p>En inglés, existe una clase de verbos auxiliares que expresan la “modalidad”:</p>
<blockquote>
<p>In linguistics and philosophy, modality is the phenomenon whereby language is used to discuss non-actual situations. For instance, a modal expression may convey that something is likely, desirable, or permissible. Quintessential modal expressions include modal auxiliaries such as English “should” <a href="https://en.wikipedia.org/wiki/Modality_(linguistics)">Descripción</a></p>
</blockquote>
<p>Según Biber (2012), los verbos modales son más comunes en la lengua hablada que en el lengua escrita. Su argumento se basa en el corpus <strong>Longman Spoken and Written English</strong> (40 millones de palabras). Examinemos la hipótesis de Biber con el BNC (100+ millones de palabras).</p>
<ul>
<li><code>BNC&gt; SPOK = "should" :: match.text_mode="spoken";</code></li>
<li><code>BNC&gt; WRIT =  "should" :: match.text_mode="written";</code></li>
<li><code>BNC&gt; size SPOK;</code></li>
<li><code>11676</code></li>
<li><code>BNC&gt; size WRIT;</code></li>
<li><code>94884</code></li>
</ul>
<p>Debemos reconocer que estos resultados parecen producir una asimetría, pero que no concuerda la hipótesis de Biber. Hasta ahora, hemos ignorado que las secciones orales y escritas del BNC no son de tamaños equivalentes. Los valores del verbo <em>should</em> se tienen que relativizar para que comparemos dos corpus de tamaños distintos. Para hacer esto, podemos pedir que el CQP nos produzca una total de palabras en las secciones correspondientes con una consulta sin ninguna restricción; es decir, unos corchetes vacíos.</p>
<ul>
<li><code>BNC&gt; ALLSPOK = [ ] :: match.text_mode="spoken";</code></li>
<li><code>BNC&gt; size ALLSPOK;</code></li>
<li><code>11983120</code></li>
<li><code>BNC&gt; ALLWRIT = [ ] :: match.text_mode="written";</code></li>
<li><code>BNC&gt; size ALLWRIT;</code></li>
<li><code>100119205</code></li>
</ul>
<p>Ahora tenemos la información cuantitativa que se necesita para poder determinar la realización relativizada (por millón de palabras-<code>wpm</code>).</p>
<ul>
<li><em>should</em><sub>BNCspoken</sub> = <span class="math inline">\(\frac{11676 x 1000000}{11983120}\)</span> = 974.3wpm</li>
<li><em>should</em><sub>BNCwritten</sub> = <span class="math inline">\(\frac{94884 x 1000000}{11983120}\)</span> = 947.4wpm</li>
</ul>
<p>Según estos resultados, se nota la preponderancia de la palabra <em>should</em> en la sección escrita (974 wpm) comparada con la sección oral (947 wpm). Estas frecuencias se llaman frecuencias relativas (‘relative frequencies’) en el sentido descrito por Brezina (2018, p. 43)</p>
<div id="la-historia-y-la-geografía" class="section level3">
<h3>La historia y la geografía</h3>
<p>Esta sección ignora una variedad de otros factores, como el registro, que sirven como vehículos sociales del uso lingüístico. Examinemos la distinción entre ‘can’ y ‘may’a través de uno de estos factores. Biber (2012, p. 203) nos dice que el verbo ’may’ se está perdiendo por cuestión del cambio lingüístico. ¿Se manifiesta este fenómeno en algún registro específico?</p>
<p>Para empezar, observemos los géneros específicos anotatos en el BNC. Podemos observar los valores de este atributo con otra consulta sin restricción, combinado con el uso del mandadto <code>group</code>.</p>
<div class="figure">
<img src="images/BNC-BABY-ALL.png" alt="" />
<p class="caption">Los géneros del BNC</p>
</div>
<p>Este ejemplo del mandato <code>group</code> nos permite observar todos los valores del atributo <code>text_derived_type</code> en el corpus. Estas categorías se describen en el documento de Susanne Flach con una tabla de los metados del BNC. Con el uso de la restricción global <code>::</code>, se puede concentrar en un género específico:</p>
<div class="figure">
<img src="images/BNC-MayCan.png" alt="" />
<p class="caption">La distribución de ‘may’ y ‘can’ en el BNC (newspaper)</p>
</div>
<p>Esta diferencia de distribuciones concuerda con lo que dice Biber cuando propone que ‘may’ es menos frecuente que ‘can’. ¿Cómo compara estos datos con el inglés de los EE.UU.? Utilizemos el <a href="http://korpus.uib.no/icame/manuals/BROWN/">Brown Corpus</a>, lo cual representa el primer corpus de tamaño grande para el inglés americano. Toma su nombre de Brown University donde fue creado en el año 1961 por Henry Kučera y W. Nelson Francis. La próxima tabla muestra de diferentes textos incluídos en este corpous.</p>
<ul>
<li>Tabla 1: Muestra de la distribución en el corpus de Brown</li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Genre</th>
<th align="left">Subgenre/Topic Area</th>
<th></th>
<th align="right">Samples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Non-fiction</td>
<td align="left">Religion</td>
<td>Books</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Periodicals</td>
<td align="right">6</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Tracts</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Skills and Hobbies</td>
<td>Books</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Periodicals</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Popular Lore</td>
<td>Books</td>
<td align="right">23</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Periodicals</td>
<td align="right">25</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Belles Lettres, Biography, Memoirs, etc.</td>
<td>Books</td>
<td align="right">38</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Periodicals</td>
<td align="right">37</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Miscellaneous</td>
<td>Government Documents</td>
<td align="right">24</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Foundation Reports</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Industry Reports</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>College Catalog</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Industry House organ</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">Learned</td>
<td>Natural Sciences</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Medicine</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Mathematics</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Social and Behavioral Sciences</td>
<td align="right">14</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Political Science, Law, Education</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Humanities</td>
<td align="right">18</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Technology and Engineering</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">Fiction</td>
<td align="left">General</td>
<td>Novels</td>
<td align="right">20</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Short Stories</td>
<td align="right">9</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Mystery and Detective</td>
<td>Novels</td>
<td align="right">20</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Short Stories</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Science Fiction</td>
<td>Novels</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Short Stories</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Adventure and Western</td>
<td>Novels</td>
<td align="right">15</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Short Stories</td>
<td align="right">14</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Romance and Love Story</td>
<td>Novels</td>
<td align="right">14</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Short Stories</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Humor</td>
<td>Novels</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Essays, etc.</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="left">Press</td>
<td align="left">Reportage</td>
<td>Political</td>
<td align="right">14</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Sports</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Society</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Spot news</td>
<td align="right">9</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Financial</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Cultural</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Editorial</td>
<td>Institutional</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td>Personal</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"></td>
<td>Letters to the Editor</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">Reviews (theatre, books, music, dance)</td>
<td></td>
<td align="right">17</td>
</tr>
</tbody>
</table>
<p>Use show cd to discover a metadata attribute that identifies a text’s “Subgenre/Topic Area” in Brown. Did you notice text_category? Again, an unconstrained query reveals what the possible values are:</p>
<p>Podemos utilizar <code>cd</code> para descubrir los atributos que identifican los “Subgenre/Topic Area” de los textos de Brown. También podemos utilizar una consulta sin restricción:</p>
<ul>
<li><code>BROWN&gt; ALL = [ ] ;</code></li>
<li><code>group ALL match text_category:</code></li>
</ul>
<p>Ahora, ¿se observa la misma asimetría entre ‘may’ y ‘can’ en el inglés americano?</p>
<div class="figure">
<img src="images/BROWN-MayCan.png" alt="" />
<p class="caption">La distribución de ‘may’ y ‘can’ en el corpus de Brown (newspaper)</p>
</div>
<p>Parece que sí; el verbo ‘may’ es menos frecuente, tanto en la muestra inglesa como en la muestra americana, que el verbo ‘can’ en los textos periodísticos.</p>
<ul>
<li><strong>Tarea:</strong> Examina los verbos ‘may’ y ‘can’ en el género <code>fiction</code>. ¿Se observa la misma asimestría? ¿Cómo se comparan los datos del inglés británico y el inglés americano? Ahora, exmamina la categoría de textos con el valor <code>learned</code> o <code>academic</code>. ¿Está disminuyendo el verbo ‘may’ en estos géneros?</li>
</ul>
</div>
</div>
<div id="contruir-una-hipótesis" class="section level2">
<h2>Contruir una hipótesis</h2>
<p>En la sección anterior, se presentó la idea de que el verbo ‘may’ está desapareciendo en inglés, tal vez debido al uso elevado del verbo ‘can’ para expresar los mismos signficados. En esta sección, examinemos nuestra propia hipótesis sobre los modales de obligación (deónticos), ‘should’ y ‘ought’.</p>
<ul>
<li><strong>Hipótesis:</strong> El verbo ‘should’ ha reemplazado la forma ‘ought’, lo cual expresa aproximadamente el mismo significado.</li>
</ul>
<p>Una hipótesis es una adivinanza educada. Sin embargo, si es verdad, debemos observar menos casos de ‘ought’ que ’should.</p>
<div class="figure">
<img src="images/BROWN-ShouldOught.png" alt="" />
<p class="caption">La distribución de ‘should’ y ‘ought’ en los corpora de Brown y del BNC</p>
</div>
<p>Parece que, sí, esta hipótesis es válida. Las tasas de atestación de ‘should’ y ‘ought’ se diferencian por un ordén de magnitud entre los dos corpus.</p>
<ul>
<li>Tabla 2: Frecuencias normalizadas en dos corpora del inglés</li>
</ul>
<table>
<colgroup>
<col width="47%" />
<col width="28%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">expresión</th>
<th align="left">Brown</th>
<th align="left">BNC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">should</td>
<td align="left"><span class="math inline">\(\frac{865 x 1M}{brownsize}\)</span> = 744wpm</td>
<td align="left"><span class="math inline">\(\frac{106597 x 1M}{bncsize}\)</span> = 950wpm</td>
</tr>
<tr class="even">
<td align="left">ought</td>
<td align="left"><span class="math inline">\(\frac{66 x 1M}{brownsize}\)</span> = 56wpm</td>
<td align="left"><span class="math inline">\(\frac{5757 x 1M}{bncsize}\)</span> = 51wpm</td>
</tr>
</tbody>
</table>
<p>Ahora, comparemos la forma modal de obligación ‘must’ con su homólogo ‘have to’. ¿Qué pensamos sobre la siguiente hipótesis?</p>
<ul>
<li><strong>Hipótesis:</strong> La estructura ‘have to’ es menos formal que ‘must’.</li>
</ul>
<p>Si esta hipótesis es correcta, esperamos tener más casos de ‘have to’ que ‘must’ en un género informal como <code>spoken_conversations</code>.</p>
<ul>
<li><code>BNC&gt; HT = "have" "to" :: match.text_derived_type="spoken_conversation";</code></li>
<li><code>BNC&gt; M = "must" :: match.text_derived_type="spoken_conversation" ;</code></li>
<li><code>BNC&gt; size HT;</code></li>
<li><code>5141</code></li>
<li><code>BNC&gt; size M;</code></li>
<li><code>2780</code></li>
</ul>
<p>Vemos que nuestra hipótesis es correcta. ¿Qué observamos en un género como la escritura académica?</p>
<ul>
<li><code>BNC&gt; M = "must" :: match.text_derived_type="academic";</code></li>
<li><code>BNC&gt; HT = "have" "to" :: match.text_derived_type="academic";</code></li>
<li><code>BNC&gt; size M ;</code></li>
<li><code>13514</code></li>
<li><code>BNC&gt; size HT ;</code></li>
<li><code>3615</code></li>
<li><code>BROWN&gt; M = "must" :: match.text_category="learned";</code><br />
</li>
<li><code>BROWN&gt; HT = "have" "to" :: match.text_category="learned";</code></li>
<li><code>BROWN&gt; size M ;</code></li>
<li><code>202</code></li>
<li><code>BROWN&gt; size HT ;</code></li>
<li><code>24</code></li>
</ul>
<p>En un género formal, se obsera que hay más casos de ‘must’ comparado con ‘have to’, un resultado que es consistente con nuestra hipótesis. [Dejamos el proceso de la normalización como una tarea de casa.]</p>
<hr />
<div id="las-listas-de-palabras" class="section level3">
<h3>Las listas de palabras</h3>
<p>El trabajo de Biber (2012) identifica tres tipos de significados que puden expresear los verbos modales del inglés:</p>
<ol style="list-style-type: decimal">
<li>permisión o posibilidad</li>
<li>obligación o necesidad lógica</li>
<li>voluntad o predicción</li>
</ol>
<p>Cada uno de estos significados se pueden asociar con una lista de palabras. El CQP ofrece un mecanismo (<a href="http://cwb.sourceforge.net/files/CQP_Tutorial.pdf">manual, sección 6.2</a>) que permite definir una lista y asociar palabras específicas con estas listas. Este proceso hace posible evitar la necesidad de escribir manualmente secuencias largas separadas por barras verticales.</p>
<ul>
<li><code>BROWN&gt; define $perm = "can could may might"</code></li>
<li><code>BROWN&gt; define $oblig = "must should ought"</code></li>
<li><code>BROWN&gt; define $volit = "will would shall"</code></li>
</ul>
<p>Estas variables, cuyos nombres comienzan con un <code>$</code>, se pueden utilizar en toda situación en la cual se podría haber utilizado una seria individual en una consulta.</p>
<ul>
<li><code>BROWN&gt; O = $oblig ;</code></li>
<li><code>BROWN&gt; group O match text_category ;</code></li>
<li><code>BNC&gt; O = $oblig ;</code></li>
<li><code>BNC&gt; group O match text_derived_type ;</code></li>
</ul>
<p>¿Qué observamos en cuanto a la formalidad con estos resultados? Ahora podemos forma la unión de todas las formas modales:</p>
<ul>
<li><code>BNC&gt; define $modal = $perm</code></li>
<li><code>BNC&gt; define $modal += $oblig</code></li>
<li><code>BNC&gt; define $modal += $volit</code></li>
<li><code>BNC&gt; show $modal</code></li>
<li><code>$modal = can could may might must should ought will would shall</code></li>
</ul>
<p>La posibilidad de referirse a todas las formas modales a la vez facilita la búsqueda de las formas modales dobles. Estas formas se aceptan en <a href="https://ygdp.yale.edu/phenomena/multiple-modals">algunas variedades del inglés</a>.</p>
<div class="figure">
<img src="images/COCA-DoubleModals.png" alt="" />
<p class="caption">Las formas modales dobles en el inglés</p>
</div>
<p>Algunos de estos casos parecen ser errores, los cuales son inevitables en un corpus. Otros casos no son modales de verdad; por ejemplo, la palabra ‘will’ se entiende también como el sustantivo <em>voluntad</em>.</p>
<ul>
<li><code>1433741433: at his will be done . And &lt;God 's will will&gt; be done voice-over And i</code></li>
<li><code>429416972: at this second gesture of &lt;good will will&gt; be met with a similar ge</code></li>
<li><code>429589131: this humanitarian aid and &lt;good will will&gt; help bring down some of</code></li>
<li><code>297895587: ple call you . Enough ill &lt;will can&gt; turn anything into an at</code></li>
<li><code>325323612:  official . But political &lt;will can&gt; be found " to do more to</code></li>
<li><code>486055689:  message to them that our &lt;will can&gt; not be broken by terror</code></li>
</ul>
<p>Sin embargo, si observamos de forma más específica los casos de la forma ‘might could’, se encuentran algunos casos legítimos. En cuanto a la comparación entre el inglés británico y el inglés americano: no existe ningún caso en el BNC y solo se encuentran dos casos en el SPOKENBNC2014, los cuales no parecen ser casos legítmos. Estas observaciones son consistentes con el uso de ‘might could’ con un fenómeno especificamente americano. (p. 44 de Hoffman et al.)</p>
<hr />
</div>
</div>
<div id="las-expresiones-regulares-con-el-cqp" class="section level2">
<h2>Las expresiones regulares con el CQP</h2>
<p>Las expresiones regulares representan una notación para especificar diferentes conjuntos de ‘strings’. Con una consulta de corpus, se utilizan las expresiones regulares para determinar el conjunto de casos posibles que podemos obtener con la consulta. Las expresiones regulares se puden utilizar en cualquier posición en el CQP y su descripción se presenta en el <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node52.html">Appendix A.1 del manual</a>. Hay una variedad de diferentes sabores de expresiones regulares; la versión de CQP del servidor utiliza expresiones regulares ’normales de unix (es decir, no son compatibles con la lengua <code>perl</code>). Por el momento, estas distinciones no nos distraen.</p>
<div id="el-wildcard" class="section level3">
<h3>El ‘wildcard’</h3>
<p>Busquemos las diferentes formas del verbo ‘drink’ en el <code>BNC-BABY</code>. Sería posible realizar consultas distintas o, por ejemplo, definir un grupo con el uso de la pipa <code>|</code>. Otra opción, es dejar que la vocal no se especifique con el símbolo <code>.</code> .</p>
<ul>
<li><code>BNC-BABY&gt; DRINK = "drink|drank|drunk" ;</code></li>
<li><code>BNC-BABY&gt; "dr.nk" ;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">drink</td>
<td align="left">552</td>
</tr>
<tr class="even">
<td align="left">drunk</td>
<td align="left">99</td>
</tr>
<tr class="odd">
<td align="left">drank</td>
<td align="left">67</td>
</tr>
</tbody>
</table>
<p>No hay que saber de antemano cuáles serán los elementos que se encuentren. Las letras ~d, r, n, y k~ se expresan explícitamente. Entonces, las expresiones regulares incluyen los tipos de palabras completas (es decir, con todas las letras explícitas) que ya hemos buscado con las consultas.</p>
</div>
<div id="clases-de-carácteres" class="section level3">
<h3>Clases de carácteres</h3>
<p>¿Cuáles son las palabras de cinco letras que empiezan con ‘gl’ y una vocal? Se puede especificar esto con el uso de las vocales ortográficas entre corchetes <code>[ ]</code>.</p>
<ul>
<li><code>BNC-BABY&gt; "gl[aeiou].." ;</code></li>
<li><code>BNC-BABY&gt; group Last match word cut 10 ;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">glass</td>
<td align="left">389</td>
</tr>
<tr class="even">
<td align="left">glory</td>
<td align="left">46</td>
</tr>
<tr class="odd">
<td align="left">gloom</td>
<td align="left">28</td>
</tr>
<tr class="even">
<td align="left">glare</td>
<td align="left">19</td>
</tr>
<tr class="odd">
<td align="left">glove</td>
<td align="left">14</td>
</tr>
<tr class="even">
<td align="left">gloss</td>
<td align="left">12</td>
</tr>
<tr class="odd">
<td align="left">glide</td>
<td align="left">11</td>
</tr>
</tbody>
</table>
<p>Este ejemplo arriba utiliza el punto dos veces para pedir casos de cinco letras, donde no se especifica el carácter específico de las dos últimas letras. Fíjate que estas consultas responden al tipo de letra (es decir, mayúscula vs. minúscula). La siguiente consulta produce casos de palabras (a) con cinco letras y (b) con una letra inicial mayúscula.</p>
<ul>
<li><code>BNC-BABY&gt; "[ABCDEFGHIJKLMNOPQRSTUVWXYZ].... ;</code></li>
</ul>
<p>Estos corchetes no son iguales a los que hemos utilizado antes con las consultas de CQP (e.g., <code>[word = "lovely"]</code>). Representan una lista explícita de los carácteres individuales que se pueden encontrar en la posición inicial de la palabra.</p>
</div>
<div id="un-rango-de-carácteres" class="section level3">
<h3>Un rango de carácteres</h3>
<p>La consulta que realizamos con las letras mayúsculas se pueden re-escribir de forma más concisa. Dentro de los corchetes, podemos especificar un rango de carácteres con el uso de un guion.</p>
<ul>
<li><code>BNC-BABY&gt; "[A-Z]...." ;</code></li>
</ul>
<p>Ahora podemos verificar que esta consulta produce los mismos resultados que la última. El ordén que se utiliza para definir los rangos sigue el <a href="https://share.ansi.org/Shared%20Documents/News%20and%20Publications/Brochures/What%20Is%20ANSI%202019%20Brochure,%20Single%20Pages.pdf">American National Standard for Information Exchange (ANSI)</a>. En el prompt de unix, puedes leer más con el mandato <code>man ascii</code>.</p>
</div>
<div id="la-morfología" class="section level3">
<h3>La morfología</h3>
<p><strong>La opcionalidad:</strong></p>
<p>Hay una variedad operadores que especifican la repetición. El signo de interrogación (<code>?</code>) indica que la expresión regular que precede es un elemento opcional; es decir, se puede repetir zero o una vez. Por ejemplo, podemos utilizar esta operador para buscar las formas singulares y plurales de una palabra como ‘dog’ si indicamos que la <em>s</em> es opcional.</p>
<ul>
<li><code>BNC-BABY&gt; "dogs?" ;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">dog</td>
<td align="left">321</td>
</tr>
<tr class="even">
<td align="left">dogs</td>
<td align="left">140</td>
</tr>
</tbody>
</table>
<p>Este operador se puede colocar en cualquier parte del string. Por ejemplo, podemos observar variaciones ortográficos del inglés británico y el americano.</p>
<ul>
<li><code>BNC-BABY&gt; "favou?r" ;</code></li>
<li><code>BNC-BABY&gt; group Last match word by match text_id cut 10 ;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Texto</th>
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ACJ</td>
<td align="left">favour</td>
<td align="left">16</td>
</tr>
<tr class="even">
<td align="left">J57</td>
<td align="left">favor</td>
<td align="left">11</td>
</tr>
</tbody>
</table>
<p>Si consultamos el texto J57 en <a href="http://www.natcorp.ox.ac.uk/docs/URG/bibliog.html">la bibliografía contenida con el Reference Guide for the British National Corpus</a>, se nota que este texto es un libro de texto sobre Inglaterra cuyo audiencia tal vez sea estudiantes americanos.</p>
<p><strong>Agrupar:</strong></p>
<p>Dentro de una expresión regular, los elementos se pueden agrupar con el uso de los paréntesis. De allí, los operadores de repetición (como <code>?</code>) se pueden aplicar al grupo entero. Esta posibilidad nos facilita el proceso de observar de la opcionalidad de, por ejemplo, el prefijo <em>un-</em> en inglés:</p>
<ul>
<li><code>BNC-BABY&gt; "(un)?thinkable" ;</code></li>
<li><code>BNC-BABY&gt; group Last match word ;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">unthinkable</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">thinkable</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
<p>o con el sufijo <em>-ren</em> de ‘children’.</p>
<ul>
<li><code>BNC-BABY&gt; "child(ren)?" ;</code></li>
<li><code>BNC-BABY&gt; group Last match word ;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">children</td>
<td align="left">1541</td>
</tr>
<tr class="even">
<td align="left">child</td>
<td align="left">782</td>
</tr>
</tbody>
</table>
<p><strong>La alternación:</strong></p>
<p>Como ya hemos visto, la barra vertical (la pipa), puede separar las series alternativas. Por ejemplo, podemos combinar el uso de los operadores de opcionalidad y de repetición para considerar más bases léxicas:</p>
<ul>
<li><code>BNC-BABY&gt; "(un)?(think|know|believ|answer|recover)able";</code></li>
<li><code>BNC-BABY&gt; group Last match word ;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">unbelievable</td>
<td align="left">21</td>
</tr>
<tr class="even">
<td align="left">unthinkable</td>
<td align="left">11</td>
</tr>
<tr class="odd">
<td align="left">recoverable</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">unanswerable</td>
<td align="left">7</td>
</tr>
<tr class="odd">
<td align="left">answerable</td>
<td align="left">6</td>
</tr>
<tr class="even">
<td align="left">unknowable</td>
<td align="left">5</td>
</tr>
<tr class="odd">
<td align="left">believable</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">thinkable</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
<p>Esta diferentes bases, separadas por barras verticales, se tratan como <strong>alternativas disyuntivas</strong>. No se aplican un operador de repetición, lo cual significa que una de las alternativas tienen que corresponder en la consulta. Además, el prefijo (la serie) <em>-able</em> tiene que aparece al final de la palabra buscada.</p>
<p>Las alternativas disjuntivas son útiles en el proceso de encontrar formas morfológicas de verbos (regulares). Para leer más sobre “Complex Regular Expression”, se debe consultar <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node52.html">el manual (A.1)</a>.</p>
<ul>
<li><code>BNC-BABY&gt; "(call|talk|help)(s|ed|ing)" ;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">called</td>
<td align="left">1279</td>
</tr>
<tr class="even">
<td align="left">talking</td>
<td align="left">740</td>
</tr>
<tr class="odd">
<td align="left">helped</td>
<td align="left">315</td>
</tr>
<tr class="even">
<td align="left">calls</td>
<td align="left">223</td>
</tr>
<tr class="odd">
<td align="left">talked</td>
<td align="left">192</td>
</tr>
<tr class="even">
<td align="left">talks</td>
<td align="left">178</td>
</tr>
<tr class="odd">
<td align="left">calling</td>
<td align="left">144</td>
</tr>
<tr class="even">
<td align="left">helping</td>
<td align="left">122</td>
</tr>
<tr class="odd">
<td align="left">helps</td>
<td align="left">80</td>
</tr>
</tbody>
</table>
<p><strong>El uso del ‘plus’ (y otros):</strong></p>
<p>El operador plus (<code>+</code>) señala que queremos una o más repeticiones de un elemento (o grupo de elementos). Como el signo de interrogación, es un operador sufijo (‘postfix’) que se aplica a la expresión regular que precede. Si el elemento o la expresión que precede es el operador de ’wildcard, podemos encontrar, por ejemplo, todas las palabras que terminan con <em>-ly</em>–es decir, los adverbios en inglés.</p>
<ul>
<li><code>BNC-BABY&gt; ".+ly" ;</code></li>
</ul>
<p>Bueno, se nota que no todos los casos encontrados son adverbios (p.e., ‘Holly’). Refinemos esta consulta mediante el rasgo que vimos con las listas de palabras (manual, sección 6.2). El operador <code>!=</code> señala que <strong>no</strong> debe corresponder (manual, sección 2.5). El signo <code>&amp;</code> significa ‘and’ y requiere que los casos encontrados concuerden con las dos restricciones especificadas–es decir, que terminen con <em>-ly</em> y que no sean “stopwords”.</p>
<ul>
<li><code>BNC-BABY&gt; define $nothanks = "Holly Billy Italy July" ;</code></li>
<li><code>BNC-BABY&gt; [ word = ".+ly" &amp; word != $nothanks ] ;</code></li>
</ul>
<p>El proceso de descubrir las excepciones (p.e. <em>Sally</em> y <em>Willy</em>) es iterativo. Al encontrar estas palabras, se pueden añadir a la lista de stopwords.</p>
<p><strong>Una cantidad específica de repeticiones:</strong></p>
<p>Las llaves (<code>{ }</code>) permiten que especifiquemos un número específico, o un rango número de repeticiones. Por ejemplo, podemos revisar una de nuestras consultas anteriores de la siguiente manera:</p>
<ul>
<li><code>BNC-BABY&gt; "gl[aeiou].{2}";</code></li>
</ul>
<p><strong>Negación de un rango:</strong></p>
<p>Además, podemos definir de manera negativa con el uso del signo de intercalación (<code>^</code>), indicado al inicio de una lista de carácteres. En este caso, estos carácteres no se deben incluir con las correspondencias. Como ejemplo, presento la siguiente consulta que intenta caracterizar todas las palabras monosilábicas del inglés con <strong>un ataque</strong> consonantal, <strong>un núcleo</strong> vocálico, y <strong>una coda</strong>, donde el ataque y la coda son opcionales y consisten de, como máximo, tres letras.</p>
<ul>
<li><code>BNC-BABY&gt; MONOSYLL = "[^aeiou]{0,3}[aeiou]+[^aeiou]{0,3}";</code></li>
</ul>
<hr />
</div>
<div id="otra-vez-con-la-morfología" class="section level3">
<h3>Otra vez con la morfología</h3>
<p>Ahora, volvamos a Wuthering Heights. Si pedimos todas las palabras que terminan con <code>-ity</code>, ¿cuáles son las categorías gramaticales que esperamos encontrar?</p>
<ul>
<li><code>WUTHERING&gt; ".+ity";</code></li>
</ul>
<p>Si consultamos el <code>info</code> de WUTHERING con el mando <code>show cd</code>. Las palabras de este corpus tienen las etiquetas de clase léxica (‘Parts of Speech’ / <code>pos</code>).</p>
<ul>
<li><code>WUTHERING&gt; group Last match pos ;</code></li>
</ul>
<p>Y, ¿qué decimos sobre las palabras que terminan con <em>-ous</em>? ¿Cuál es la léxica de estas palabras? Utilicemos el atributo de <code>pos</code> de WUTHERING para probar esta cuestión. Podemos pedir que el CQP nos muestre en el KWIC (‘Key-Words-In-Context’) estas etiquetas con el siguiente mandato:</p>
<ul>
<li><code>WUTHERING&gt; show +pos ;</code></li>
</ul>
<p>Cambiamos este valor con el siguiente mandato <code>show -pos</code>. Las etiquetas para las clases léxicas se pueden leer en <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node53.html">el manual (sección A.2.0.1)</a>.</p>
<p>Ahora busquemos las palabras con el sufijo <em>-ful</em>.</p>
<ul>
<li><code>WUTHERING&gt; ".+ful" ;</code></li>
<li><code>WUTHERING&gt; group Last match pos ;</code></li>
</ul>
<p>¿Qué encontramos? ¿Cuáles son las clases léxicas de las palabras excepcionales (es decir, palabras que no sean adjetivos) como ‘spoonful’ y ‘mouthful’? Utilicemos una consulta disjuntiva para encontrar todos los miembros de esta categoría minoritaria.</p>
<ul>
<li><code>WUTHERING&gt; [ word = ".+ful" &amp; pos=ALGO QUE TÚ ESPECIFICAS];</code></li>
</ul>
<p>¿Y qué pasa con el sufijo <code>-less</code>? ¿Cuál son los marcadores discursivos que no sigan la generalización? Hagamos la misma búsqueda con el subconjunto de Wuthering Heights que se encuentra en el BNC.</p>
<ul>
<li><code>BNC&gt; ".+less" :: match.text_id = "GWH" ;</code></li>
<li><code>68775950: /PRF a/AT0 wild/AJ0 ,/PUN &lt;hatless/AJ0&gt; girl/NN1 ,/PUN we/PNP sa</code></li>
<li><code>68776660: VVD ,/PUN hot/AJ0 and/CJC &lt;breathless/AJ0&gt; ./PUN ``/PUQ That/DT0 'l</code></li>
<li><code>68778512: you/PNP tonight/AV0 ,/PUN &lt;unless/CJS&gt; perhaps/AV0 I/PNP set/VV</code></li>
<li><code>68780542: N1 ,/PUN wild/AJ0 and/CJC &lt;breathless/AJ0&gt; ./PUN She/PNP threw/VVD</code></li>
<li><code>68788920: ,/PUN and/CJC arrived/VVD &lt;breathless/AJ0&gt; at/PRP Wuthering/VVG Hei</code></li>
<li><code>68791639: y/PRP next/ORD summer/NN1 &lt;unless/CJS&gt; you/PNP help/VVB him/PNP</code></li>
</ul>
<p>Se puede consultar <a href="http://ucrel.lancs.ac.uk/claws5tags.html">el conjunto de etiquetas (CLAWS5) aquí</a>. Esta comparación muestra que el mismo texto se puede interpretar con dos equemas diferentes de anotación léxica. Cada equema viene con su propia perspectiva teórica.</p>
</div>
<div id="tareas-8-de-sept." class="section level3">
<h3>Tareas (8 de sept.)</h3>
<p><strong>1a Parte:</strong> Con el uso del atributo <code>pos</code>, utiliza CQP para encontrar los sustantivos más observados en el corpus de Ancora. Determina si este resultado es esperado o no esperado de acuerdo con el “sampling frame” de Ancora (según el capítulo 1, sección 1.4 de Brezina).</p>
<p><strong>2a Parte:</strong> ¿Cuáles son la segunda palabra y la tercera palabra más observadas en el corpus Ancora que (a) tienen una letra mayúscula inicial y (b) continúan con todas letras minúsculas? Crea una expresión regular para encontrar estas palabras que exluya las siglas. Otra vez, compara tus resultados con el sampling frame de Ancora.</p>
<p><strong>3a Parte:</strong> Utiliza los operadores de alternativas y de repetición para crear una expresión regular que encuentre todas las formas del presente <a href="https://www.wordreference.com/conj/FrVerbs.aspx?v=lire">del verbo <em>lire</em> ‘to read’</a> del francés. Utiliza el corpus FRWAC para buscar estas formas del verbo <em>lire</em>.</p>
<p>Verifique los resultados por una consulta de <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/french-tagset.html">las clases léxicas observadas</a>. ¡Cuidado! La palabra francesa para ‘cama’ tiene la misma forma ortográfica que una de las formas verbales del verbo <em>lire</em>. Revisa tu consulta para que las formas de ciertas clases léxicas se excluyan.</p>
<hr />
</div>
</div>
</div>
<div id="a-semana-2" class="section level1">
<h1>4a Semana</h1>
<div id="más-sobre-las-clases-léxicas" class="section level2">
<h2>Más sobre las clases léxicas</h2>
<p>Como que describimos en la clase anterior, muchos corpus tienen las anotaciones léxicas. El CQP permite que definamos fácilimente una búsqueda con etiquetas particulares. El siguiente ejemplo muestra las palabras con la etiqueta del determinante <code>DT</code>.</p>
<ul>
<li><code>DICKENS&gt; [ pos = "DT" ] cut 10;</code></li>
<li><code>&lt;A&gt; CHRISTMAS CAROL by Charl</code></li>
<li><code>ens I have endeavoured in &lt;this&gt; Ghostly little book , to</code></li>
<li><code>ly little book , to raise &lt;the&gt; Ghost of an Idea , which</code></li>
<li><code>k , to raise the Ghost of &lt;an&gt; Idea , which shall not p</code></li>
</ul>
<p>Podemos pedir que las etiquetas se vean con el siguiente mandato:</p>
<ul>
<li><code>DICKENS&gt; show +pos;</code></li>
<li><code>&lt;A/DT&gt; CHRISTMAS/NP CAROL/NN by</code></li>
<li><code>10: VBP endeavoured/VBN in/IN &lt;this/DT&gt; Ghostly/JJ little/JJ boo</code></li>
<li><code>17: ook/NN ,/, to/TO raise/VB &lt;the/DT&gt; Ghost/NN of/IN an/DT Ide</code></li>
</ul>
<p>Con los corpus tempranos, las etiquetas se asignaron manualmente; luego, estos datos manuales sirvieron como apoyo estadístico para los “POS-Taggers” automáticos que son imperfectos. Fue medio complicado el proceso de determinar las etiqutas. Por ejemplo, en <a href="https://repository.upenn.edu/cis_reports/570/">el trabajo de Beatrice Santorini (1990)</a> se describen algunas decisiones confusas en la sección “Confusing Parts of Speech” (p. 9.)</p>
</div>
<div id="algunas-búsquedas" class="section level2">
<h2>Algunas búsquedas</h2>
<div id="cuáles-son-los-sustantivos-comunes-más-utilizados-por-charles-dickens" class="section level3">
<h3>¿Cuáles son los sustantivos comunes más utilizados por Charles Dickens?</h3>
<ul>
<li><code>DICKENS&gt; Nouns = [ pos = "NN" ];</code></li>
<li><code>DICKENS&gt; group Nouns match word cut 2000;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">man</td>
<td align="left">5923</td>
</tr>
<tr class="even">
<td align="left">time</td>
<td align="left">5100</td>
</tr>
<tr class="odd">
<td align="left">Mrs</td>
<td align="left">3797</td>
</tr>
<tr class="even">
<td align="left">hand</td>
<td align="left">3530</td>
</tr>
<tr class="odd">
<td align="left">head</td>
<td align="left">3479</td>
</tr>
<tr class="even">
<td align="left">gentleman</td>
<td align="left">3319</td>
</tr>
<tr class="odd">
<td align="left">sir</td>
<td align="left">3289</td>
</tr>
<tr class="even">
<td align="left">way</td>
<td align="left">3247</td>
</tr>
<tr class="odd">
<td align="left">face</td>
<td align="left">2985</td>
</tr>
<tr class="even">
<td align="left">day</td>
<td align="left">2730</td>
</tr>
<tr class="odd">
<td align="left">night</td>
<td align="left">2571</td>
</tr>
<tr class="even">
<td align="left">door</td>
<td align="left">2543</td>
</tr>
<tr class="odd">
<td align="left">lady</td>
<td align="left">2511</td>
</tr>
<tr class="even">
<td align="left">room</td>
<td align="left">2367</td>
</tr>
<tr class="odd">
<td align="left">house</td>
<td align="left">2223</td>
</tr>
<tr class="even">
<td align="left">nothing</td>
<td align="left">2133</td>
</tr>
<tr class="odd">
<td align="left">friend</td>
<td align="left">2022</td>
</tr>
</tbody>
</table>
</div>
<div id="entre-dos-palabras" class="section level3">
<h3>Entre dos palabras</h3>
<p>Los corchetes vacíos se pueden utilizar elementos sin propiedades. Con otras expresiones regulares, como el plus, podemos especificar que, por lo menos debe haber un elemento que ocurre entre dos palabras.</p>
<ul>
<li><code>DICKENS&gt; "either" []+ "or";</code></li>
<li><code>...</code></li>
<li><code>DICKENS&gt; size Last;</code></li>
<li><code>453</code></li>
</ul>
<p>Ahora podemos imponer más restricciones con esta consulta. Por ejemplo, podemos requerir que los casos aparezcan en posición interna de oración o podemos eliminar los casos de ‘either’ como un determinante. Acordáos que el signo de exclamación es el operador de negación (manual, sección 2.6).</p>
<ul>
<li><code>DICKENS&gt; [ word="either" &amp; !pos="DT"] []+ "or" within s;</code></li>
<li><code>DICKENS&gt; size Last;</code></li>
<li><code>199</code></li>
</ul>
<p>Podemos seguir con aun más restricciones. Por ejemplo, podemos requerir que solo pueda haber cinco o menos casos entre ‘either’ y ‘or’.</p>
<ul>
<li><code>DICKENS&gt; [ word="either" &amp; !pos="DT"] []{1,5} "or" withi</code>n s;`</li>
<li><code>DICKENS&gt; size Last;</code></li>
<li><code>131</code></li>
</ul>
</div>
<div id="los-verbos-frasales-con-out" class="section level3">
<h3>Los verbos frasales con “out”</h3>
<p>¿Cuáles son los verbos que co-ocurren con la palabra “out”? Este ejemplo incluye el uso de las consultas nombradas. El signo arroba (<code>@</code>) determina el blanco. Los usuarios del CQP pueden agrupar los resultados según el blanco de la consulta. En este caso, el mandato <code>cut</code> define un límite; es decir, los resultados que se observan menos de 10 veces no se muestran.</p>
<ul>
<li><code>DICKENS&gt; PhrasalV = @[ pos="V.*" ] [ word="out" ];</code></li>
<li><code>DICKENS&gt; group PhrasalV target word cut 10;</code></li>
</ul>
<p><strong>Pregunta</strong> ¿Son todos estos casos “verbo” + “out”? ¿Cómo se sabe?</p>
</div>
<div id="más-con-secuencias-de-palabras" class="section level3">
<h3>Más con secuencias de palabras</h3>
<p>Podemos utilizar las expresiones regulares al nivel del de los casos también (<a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node13.html">sección 2.7 del manual</a>).</p>
<ul>
<li><code>DICKENS&gt; [pos = "IN"] [pos = "DT"]? ( [pos = "RB"]? [pos = "JJ.*"]) * [pos = "N.*"]+ ;</code></li>
</ul>
<p>¿Qué significa exactamente esta consulta?</p>
</div>
<div id="el-caso-en-el-alemán" class="section level3">
<h3>El caso en el alemán</h3>
<p>El mandato <code>show</code> revela otro nivel de anotación. Consideremos las Figuras 7 y 8 de <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node39.html">la sección 6.6 del manual</a>. Verifique que tu terminal esté configurado para la visualización de Latin1, y no UTF8. (Por ejemplo, Mac OS X Terminal: Preferences &gt; Settings &gt; Advanced. Después, encuentra la sección llamada “International” y verifique que el “Character encoding” esté configurado para el conjunto de ISO Latin 1. Con el PuTTY de Windows, hay que seleccionar ISO-8859 en <a href="http://the.earth.li/~sgtatham/putty/0.65/htmldoc/Chapter4.html#config-translation">el Translation panel</a>.</p>
<ul>
<li><code>GERMAN-LAW&gt; show +agr;</code></li>
<li><code>GERMAN-LAW&gt; [ pos= "ART" &amp; agr contains "Akk.*" ] cut 10 ;</code></li>
</ul>
<p>¿Se entiende porqué el atributo <code>agr</code> tiene varios elementos? Examinemos cuidadosamente los determinantes del alemán que empiezan con la letra <d>. ¿Cuáles son los determinantes que sean claramente <strong>nominativos</strong>? Cuáles son los determinantes que sean claramente <strong>acusativos</strong>?</p>
<ul>
<li><code>GERMAN-LAW&gt; dacc = [ pos= "ART" &amp; word="[dD].*" &amp; agr contains "Akk.*" ];</code></li>
<li><code>GERMAN-LAW&gt; dnom = [ pos= "ART" &amp; word="[dD].*" &amp; agr contains "Nom.*" ];</code></li>
<li><code>GERMAN-LAW&gt; group dacc match word ;</code></li>
<li><code>GERMAN-LAW&gt; onlyacc = difference dacc dnom ;</code></li>
<li><code>GERMAN-LAW&gt; onlynom = difference dnom dacc;</code></li>
<li><code>GERMAN-LAW&gt; group onlynom match word ;</code></li>
<li><code>GERMAN-LAW&gt; group onlyacc match word ;</code></li>
</ul>
<p>El operador <code>set</code> se introduce en <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node21.html">la sección 3.5 del manual</a>.</p>
</div>
<div id="los-grupos-verbales-en-el-francés" class="section level3">
<h3>Los grupos verbales en el francés</h3>
<p>La instalación del CQP está configurado para el uso de la colección Europarl 3 de los dabates parlimentarios de la U.E. entre los años 1996 y 2003. Esta colección incluye 40 millones de palabaras en cada una de seis lenguas: inglés, alemán, francés, italiano y holandés. Las categorías léxicas se asignaron automaticamente con el uso de TreeTagger. El conjunto de etiquetas para cada lengua se describen en <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/">el sitio de TreeTagger</a>. Consideremos <a href="https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/french-tagset.html">las etiquetas para el francés</a>, en las cuales se distinguen los verbos infinitos de otros.</p>
<ul>
<li><code>EUROPARL-FR&gt; show +pos ;</code></li>
<li><code>EUROPARL-FR&gt; InfVCluster = @[ pos = "VER:infi"] [ pos = "VER.infi"]+  ;</code></li>
<li><code>EUROPARL-FR&gt; group InfVCluster target word cut 100;</code></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">faire</td>
<td align="left">12658</td>
</tr>
<tr class="even">
<td align="left">pouvoir</td>
<td align="left">8360</td>
</tr>
<tr class="odd">
<td align="left">s</td>
<td align="left">2206</td>
</tr>
<tr class="even">
<td align="left">vouloir</td>
<td align="left">1753</td>
</tr>
<tr class="odd">
<td align="left">devoir</td>
<td align="left">1441</td>
</tr>
<tr class="even">
<td align="left">voir</td>
<td align="left">1273</td>
</tr>
<tr class="odd">
<td align="left">laisser</td>
<td align="left">1135</td>
</tr>
<tr class="even">
<td align="left">l</td>
<td align="left">845</td>
</tr>
<tr class="odd">
<td align="left">savoir</td>
<td align="left">689</td>
</tr>
<tr class="even">
<td align="left">m</td>
<td align="left">463</td>
</tr>
<tr class="odd">
<td align="left">entendre</td>
<td align="left">295</td>
</tr>
<tr class="even">
<td align="left">aller</td>
<td align="left">275</td>
</tr>
<tr class="odd">
<td align="left">d</td>
<td align="left">256</td>
</tr>
<tr class="even">
<td align="left">venir</td>
<td align="left">224</td>
</tr>
<tr class="odd">
<td align="left">espérer</td>
<td align="left">165</td>
</tr>
<tr class="even">
<td align="left">prétendre</td>
<td align="left">137</td>
</tr>
<tr class="odd">
<td align="left">oser</td>
<td align="left">129</td>
</tr>
<tr class="even">
<td align="left">n</td>
<td align="left">115</td>
</tr>
<tr class="odd">
<td align="left">dire</td>
<td align="left">100</td>
</tr>
</tbody>
</table>
<p>Si encontramos el verbo “faire”, podemos explorar su significado de estos grupos con el uso de los <strong>aligned corpora</strong>.</p>
<div class="figure">
<img src="images/AlignedCorpora.png" alt="" />
<p class="caption">Los corpus alineados del Europarl 3 al nivel de la oración (Koehn 2005)</p>
</div>
<p>El “context descriptor” (cd) indica cuáles son los corpus alineados con el corpus seleccionado.</p>
<ul>
<li><code>EUROPARL-FR&gt; show cd;</code></li>
<li><code>===Context Descriptor==================================</code></li>
<li><code>.....</code></li>
<li><code>Aligned Corpora:</code></li>
<li><code>europarl-nl</code></li>
<li><code>europarl-de</code></li>
<li><code>europarl-en</code></li>
<li><code>europarl-es</code></li>
<li><code>europarl-it</code></li>
<li><code>=======================================================</code></li>
</ul>
<p>Con el mandato <code>show</code>, podemos cambiar el alineamiento. Este cambio significa que cada caso estará acompañado por la oración correspondiente del mismo alineamiento.</p>
<ul>
<li><code>EUROPARL-FR&gt; show -pos ;</code></li>
<li><code>EUROPARL-FR&gt; set context sentence;</code></li>
<li><code>EUROPARL-FR&gt; faireVinf = [ word="faire" ] @[ pos="VER:infi"] ;</code></li>
<li><code>EUROPARL-FR&gt; show +europarl-en ;</code></li>
<li><code>EUROPARL-FR&gt; cat faireVinf cut 100;</code></li>
</ul>
<p><strong>Ejercicio:</strong> Basado en el texto alineado del inglés, ¿cómo traduciríamos <em>faire avancer</em> o <em>faire passer</em>? ¿Cómo traduciríamos estas estructuras al español?</p>
</div>
<div id="los-grupos-con-faire-en-francés-e-italiano" class="section level3">
<h3>Los grupos con <em>faire</em> en francés e italiano</h3>
<p>¿Cuál elemento viene después del grupo verbal con <em>faire</em> en francés?</p>
<ul>
<li><em>le,la</em> vs. <em>lui,leu</em> + <em>faire</em> + VER:infi + <strong>blanco</strong></li>
<li>pronombre + ‘hacer’ + verbo infinito + categoría desconocida</li>
</ul>
<p>Para investigar esta pregunta, haremos dos consultas, una que contiene los casos donde un pronombre de objeto directo precede el verbo <em>faire</em> y otra donde un pronombre de objeto indirecto precede el verbo <em>faire</em>. Eliminemos los casos que ocurren en posición final de oración y los casos que terminan con un signo de puntuación.</p>
<ul>
<li><code>EUROPARL-FR&gt; define $faire = "fais fait faisons faites font faire";</code></li>
<li><code>EUROPARL-FR&gt; direct = [ word="le|la" ] [ word=$faire ] [ pos="VER:infi"] @[ pos != "SENT|PUN"];</code></li>
<li><code>EUROPARL-FR&gt; indirect = [ word="lui|leur" ] [ word=$faire ] [ pos="VER:infi"] @[ pos != "SENT|PUN"];</code></li>
<li><code>EUROPARL-FR&gt; group direct target word by target pos ;</code></li>
<li><code>EUROPARL-FR&gt; group indirect target word by target pos ;</code></li>
</ul>
<p>Si el grupo con <em>faire</em> está precedida por un pronombre de objeto directo, observamos que las palabras más populares son las preposiciones como <em>à</em> ‘to’, <em>dans</em> ‘inside’, o <em>en</em> ‘in’. Si el group está precedida por un pronombre de objeto indirecto, estas palabras apenas se observan.</p>
<p>De hecho, los cuatro casos que ocurren con <em>à</em> son todos adjuntos temporales:</p>
<ul>
<li><code>EUROPARL-FR&gt; anomalous = [ word="lui|leur" ] [ word=$faire ] [ pos="VER:infi"] @[ word="à"];</code></li>
<li><code>EUROPARL-FR&gt; set RightContext 2 s ;</code></li>
<li><code>EUROPARL-FR&gt; cat anomalous ;</code></li>
</ul>
<p>Un pronombre de objeto indirecto que precede la construcción <em>faire</em> + verbo infinito corresponde con el objeto indirecto del verbo infinitivo. Este elemento es, probablemente, el recipiente, lo cual se habría marcado con una preposición si hubiera ocurrido en posicón posverbal (<a href="https://www.thoughtco.com/french-causative-le-causatif-1368818">lección sobre el francés</a>).</p>
<p>Además, podemos realizar esta consulta para el italiano:</p>
<ul>
<li><code>EUROPARL-IT&gt; define $fare = "faccio fai fa facciamo fate fanno fare far";</code></li>
<li><code>EUROPARL-IT&gt; direct = [ word="lo|li" ] [ word=$fare ] [ pos="VER:infi" ] @[ pos != "SENT|PON"];</code></li>
<li><code>EUROPARL-IT&gt; indirect = [ word="gli" ] [ word=$fare ] [ pos="VER:infi" ] @[ pos != "SENT|PON"];</code></li>
</ul>
<p>Otra vez, si un pronombre de objeto directo precede el grupo verbal, los complementos preposicionales son acaptables. Si un pronombre de objeto indirecto precede el grupo, casi no se observan los complementos preposicionales.</p>
<ul>
<li><code>EUROPARL-IT&gt; group direct target word by target pos;</code></li>
<li><code>EUROPARL-IT&gt; group indirect target word by target pos;</code></li>
</ul>
<p>El único caso anómolo, “gli fanno perdere di vista”, se traduce así: “lose sight of”. Esto sugiere que la preposición “di” sirve como parte de un complejo verbal “perdere di vista.”</p>
<p><strong>Ejercicio:</strong> Investigemos el español del mismo modo. Empezemos con el verbo <em>hacer</em> y la distinción entre <em>lo,la</em> vs. <em>le</em>. ¿Tiene español el mismo comportamiento que el francés y el italiano con respeto a los complementos preposicionales después de los grupos verbales que son precedidos por pronombres de objeto directo vs. indirecto?</p>
<hr />
</div>
</div>
</div>
<div id="a-semana-3" class="section level1">
<h1>5a Semana</h1>
<div id="atributos-posicionales" class="section level2">
<h2>Atributos posicionales</h2>
<p>Como ya hemos visto, muchos de los corpus tienen las anotaciones para clases léxicas que se pueden utilar con el atributo <code>pos</code>. Por ejemplo, el corpus COCA tiene las anotaciones basadas en <a href="http://ucrel.lancs.ac.uk/claws7tags.html">el claws C7 tagset</a>. Aunque todos los sub-tipos de verbso llevan etiquetas distintas, todas las etiquetas de los elementos verbales empiezan con la letra ‘v’.</p>
<ul>
<li><code>COCA&gt; VERBS = [ pos="v.*" ] ;</code></li>
<li><code>COCA&gt; group VERBS match lemma cut 1000000 ;</code></li>
</ul>
<p>Las combinaciones de diferentes etiquetas de clases léxicas nos facilitan el proceso de encontrar construcciones específicas. Por ejemplo, para encontrar un objeto directo que ocurre durante los dos espacios después de un verbo donde no interviene un complementizador, podemos realizar la siguiente consulta:</p>
<ul>
<li>COCA&gt; VOBJ = [ pos="v.*" ] [ pos != "cs.*"]{0,2} [ pos=“nn(1|2)?”] ;</li>
</ul>
<p>Esta consulta no se permite mediante <a href="https://www.english-corpora.org/coca/">el sitio de web del COCA</a>. ESte tipo de anotación al nivel de la palabra, no se limita a la morfosintáxis. El corpus SPOKENBNC2014 viene con una anotación conceptual-semántica que se llama <a href="http://ucrel.lancs.ac.uk/usas/">USAS</a>. Esta anotación se puede utilizar para encontrar, por ejemplo, las palabras relacionadas con los cigarrillos, es decir, la categoría <code>F3</code> según la tabla de USAS.</p>
<ul>
<li><code>SPOKENBNC2014&gt; VICE = [ usas="F3" ] ;</code></li>
<li><code>SPOKENBNC2014&gt; group VICE match word  cut 30;</code></li>
</ul>
<p>Exactamente como podemos utilizar <code>show +pos</code> y <code>show -pos</code> para activar o reprimir la muestra de las etiquestas, también podemos mostrar las anotaciones de USAS en el SPOKENBNC2014 con el mandato <code>show +usas</code>.</p>
<div id="el-modelo" class="section level3">
<h3>El modelo</h3>
<p>Para los atributos posicionales, el modelo subyacente es una tabla donde cada fila es una palabra y cada atributo es una columna, como se observa en la siguiente tabla.</p>
<div class="figure">
<img src="images/ModeloAtributosPosicionales.png" alt="" />
<p class="caption">Model de los datos con los atributos posicionales</p>
</div>
</div>
</div>
<div id="los-atributos-estructurales" class="section level2">
<h2>Los atributos estructurales</h2>
<p>Nuestro sistema de corpus diferencia los atributos posicionales de los atributos estructurales. Como ya hemos visto, el segundo se utilizan en muchos casos para indicar los metadatos. Por ejemplo:</p>
<ol style="list-style-type: decimal">
<li>Las obras de Shakespeare se identifican por el título: <code>text_title="Romeo and Juliet"</code></li>
<li>Las expresiones del BNC se clasifican con la edad del hablantes: <code>u_age_group="15-24"</code>.</li>
<li>Las muestras de textos de BROWn son divididas por el sub-género: `text_category=“romance|science_fiction”.</li>
</ol>
<p>Estos atributos estructurales se pueden considerar como elementos invisibles, por ejemplo <code>&lt;text_category&gt;</code>, que aparecen al princippio de cada extracto individual representado en BROWN. Dentro de estos corchetes angulures, se observa también otro símbolo de indica la categoría textual–news, editorial, reviews, religion, etc.</p>
<ul>
<li><code>&lt;text_category news&gt;The Fulton County Grand Jury s</code></li>
<li><code>&lt;text_category editorial&gt;Assembly session brought</code></li>
<li><code>&lt;text_category reviews&gt;It is not news that Nathan</code></li>
<li><code>&lt;text_category religion&gt;As a result , although we</code></li>
<li><code>&lt;text_category hobbies&gt;Too often a beginning bodyb</code></li>
<li><code>&lt;text_category lore&gt;In American romance , almost n</code></li>
<li><code>&lt;text_category belles_lettres&gt;Northern liberals ar</code></li>
<li><code>&lt;text_category government&gt;The Office of Business E</code></li>
<li><code>&lt;text_category learned&gt;1 . Introduction It has rec</code></li>
<li><code>&lt;text_category fiction&gt;Thirty-three Scotty did not</code></li>
<li><code>&lt;text_category mystery&gt;There were thirty-eight pat</code></li>
<li><code>&lt;text_category science_fiction&gt;Now that he knew hi</code></li>
<li><code>&lt;text_category adventure&gt;Dan Morgan told himself h</code></li>
<li><code>&lt;text_category romance&gt;They neither liked nor disl</code></li>
<li><code>&lt;text_category humor&gt;It was among these that Hinkl</code></li>
</ul>
<p>Estos elementos que aparacen al principio del extracto (<code>&lt;text_category&gt;</code>) van juntos con otro elemento que ocurre al final del extracto (<code>&lt;/text_category&gt;</code>).</p>
<ul>
<li><code>asn't a bit of trouble '' .&lt;/text_category&gt;</code></li>
<li><code>pendency and illegitimacy .&lt;/text_category&gt;</code></li>
<li><code>esident Kennedy's in 1961 .&lt;/text_category&gt;</code></li>
<li><code>ons under 18 years of age .&lt;/text_category&gt;</code></li>
<li><code>for the simplest offense .&lt;/text_category&gt;</code></li>
<li><code>on the national committee .&lt;/text_category&gt;</code></li>
<li><code>or a coalition Government .&lt;/text_category&gt;</code></li>
<li><code>some of these criticisms .&lt;/text_category&gt;</code></li>
<li><code>m a government on its own .&lt;/text_category&gt;</code></li>
<li><code>es and presented its case .&lt;/text_category&gt;</code></li>
</ul>
<p>Estos elementos no son casos (tokens), pero sí delimitan diferentes regiones del corpus; es decir, tienen un comienzo y un fin. Visto de esta manera, parecen mucho a las etiquetas con corchetas angulares que se utilizan en otros tipos de <a href="https://en.wikipedia.org/wiki/IBM_Generalized_Markup_Language">markup languages como SGML, HTML y XML</a>. El “eXtensible” markup language XML es una de las opciones más populares para la anotación de los corpus de lenguas naturales. <a href="http://www.nltk.org/book/ch11.html#sec-working-with-xml">Las secciones 4.1 y 4.2 del capítulo 11 del libro de NLTK (Natural Language Tool Kit)</a> explican cómo se utiliza XML para separar las anotaciones lingüísticas de los textos anotados.</p>
<p>Abajo se presenta la forma subyacente del BNC, anotada con XML antes de que se haya preparado para el uso con el CQP. Cada palabra empieza y termina con los símbolos <code>&lt;w&gt;</code> y <code>&lt;/w&gt;</code>. El elemento <code>w</code> tiene el atributo <code>c5</code> de las etiquetas de CLWAS-C5 y el elemento <code>hw</code> para headword.</p>
<ul>
<li><code>&lt;w c5="NP0" hw="michael" pos="SUBST"&gt;Michael&lt;/w&gt;</code></li>
<li><code>&lt;w c5="NP0" hw="palin" pos="SUBST"&gt;Palin&lt;/w&gt;</code></li>
<li><code>&lt;w c5="VVZ" hw="seem" pos="VERB"&gt;seems&lt;/w&gt;</code></li>
<li><code>&lt;w c5="AT0" hw="an" pos="ART"&gt;an&lt;/w&gt;</code></li>
<li><code>&lt;w c5="AJ0" hw="unlikely" pos="ADJ"&gt;unlikely&lt;/w&gt;</code></li>
<li><code>&lt;w c5="NN1" hw="double" pos="SUBST"&gt;double&lt;/w&gt;</code></li>
<li><code>&lt;w c5="PRP" hw="for" pos="PREP"&gt;for&lt;/w&gt;</code></li>
<li><code>&lt;w c5="AT0" hw="the" pos="ART"&gt;the&lt;/w&gt;</code></li>
<li><code>&lt;w c5="AJ0" hw="archetypal" pos="ADJ"&gt;archetypal&lt;/w&gt;</code></li>
<li><code>&lt;w c5="NN1-AJ0" hw="stiff" pos="SUBST"&gt;stiff&lt;/w&gt;</code></li>
<li><code>&lt;w c5="VVD-AJ0" hw="upperlip" pos="VERB"&gt;upperlipped&lt;/w&gt;</code></li>
<li><code>&lt;w c5="AJ0" hw="phlegmatic" pos="ADJ"&gt;phlegmatic&lt;/w&gt;</code></li>
<li><code>&lt;w c5="NP0-NN1" hw="englsihman" pos="SUBST"&gt;Englsihman&lt;/w&gt;</code></li>
<li><code>&lt;w c5="NP0" hw="phileas" pos="SUBST"&gt;Phileas&lt;/w&gt;</code></li>
<li><code>&lt;w c5="NP0" hw="fogg" pos="SUBST"&gt;Fogg&lt;/w&gt;</code></li>
<li><code>&lt;c c5="PUN"&gt;, &lt;/c</code>&gt;`</li>
</ul>
<p>Podemos comparar esta anotación con la figura 5 de Gries y Berez 2017. Las figuras 3, 6, y 18 de ese capítulo ilustra otras maneras de utilizar XML con los corpus lingüísticos anotados.</p>
<p>Según la manera en que el corpus fue anotado, estas anotaciones de XML se pueden utilizar de manera más o menos directa en las búsquedas. Por ejemplo, en la forma subyacente del XML del corpus de DICKENS, los sintagmas nominales y los sintagmas preposiciones son anotados, como se muestra en el siguiente ejemplo sacado de <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node27.html">la sección 4.3 del manual</a>.</p>
<p><img src="images/SyntacticAnnotation.png" alt="Anotación sintáctica" /> Con esta anotaciones, podemos realizar una consulta con las etiquetas <code>&lt;np&gt;</code> y <code>&lt;\np&gt;</code>. Por ejemplo, la siguiente búsqueda pide los casos de sintagmas nominales que empiezan con “a”, “some”, o “many”:</p>
<ul>
<li><code>DICKENS&gt; INITIALQUANT = &lt;np&gt; [word = "a|some|many" ] ;</code></li>
</ul>
<p>Podemos utilizar otras combinaciones de etiquetas iniciales y finales. La siguiente consulta encuentra todos los sintagmas nominales que contienen la palabra “door”:</p>
<ul>
<li><code>DICKENS&gt; DOORPP = &lt;pp&gt; []* "door" []* &lt;/pp&gt; ;</code></li>
</ul>
<p>El elemento <code>within</code> permite que simplifiquemos la consulta:</p>
<ul>
<li><code>DICKENS&gt; D = "door" within pp;</code></li>
</ul>
</div>
<div id="el-modelo-subyacente" class="section level2">
<h2>El modelo subyacente</h2>
<p>El modelo completo del CWB (Corpus Work Bench) combina las anotaciones al de los casos y las anotaciones al nivel de las regiones:</p>
<p><img src="images/ModeloCompleto.png" alt="El model completo de los datos de CQP que incluye las etiquetas XML" /> ## Los atributos estructurales (‘s-attributes’)</p>
<p>Las regiones se pueden delimitar con las etiquetas XML. Estas etiquetas también pueden tener diferentes propiedades. Al compilar el corpus, estas propiedades se definen una vez, en vez de definirlas para casa caso.</p>
<div id="la-duración" class="section level3">
<h3>La duración</h3>
<p>Por ejemplo, en el corpus de DICKENS tanto la duración de las palabras (<code>lens</code>) como la cabeza sintáctica (<code>h</code>) de los sintagmas nominales son indicados. El atributo de duración se convierte en <code>np_len</code> dentro del CQP. Este atributo se puede utilizar con una expresión regular (es decir, <code>3|4|5|6</code>) o se puede cambiar a un valor con el rasgo del CQP <code>int()</code>. Este rasgo permite que utilice propiedades como “más de” y “menos de”:</p>
<ul>
<li><code>DICKENS&gt; DOORNP = &lt;np&gt; [ word != "," ]* d:"door" [ word != ","]* &lt;/np&gt; :: int(d.np_len) &gt; 7;</code></li>
</ul>
<p>Esta búsqueda intenta encontrar los sintagmas nominales largas en el corpus de DICKENS que mencionan una puerta pero que no contienen una comma. En esta búsqueda, la lentra <code>d</code> minúscula funciona como un label, como se explica en <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node25.html">la sección 4.1 del manual</a>. Es similar al signo <code>@</code>, lo cual determina el blanco de la búsqueda.</p>
</div>
<div id="el-género" class="section level3">
<h3>El género</h3>
<p>Como ya se sabe, en el español las palabras son especificadas por el género gramatical (masculina vs. femenina). El corpus ANCORA viene con etiquetas para las constituyentes sintácticas como los sintagmas nominales (<code>grup.nom</code>), sintagmas verbales (<code>grup.verb</code>), etc. La forma XML tiene la siguiente estructura:</p>
<div class="figure">
<img src="images/XMLAnCora.png" alt="" />
<p class="caption">XML del AnCora</p>
</div>
<p>Como los atribuotos de <code>h</code> y <code>len</code> de DICKENS, los atributos XML <code>gen</code> y <code>num</code> en el corpus de AnCora se han convertido en atributos estructurales especializados para la constituyente sintáctica donde se manifiestan. Consideremos los sintagmas (<code>grup</code>) que son adjetivales (<code>a</code>) y que son clasificados por género (<code>gen</code>).</p>
<ul>
<li><code>ANCORA&gt; P = [ lemma="primero" ];</code></li>
<li><code>ANCORA&gt; group P match grup_a_gen by match word cut 30;</code></li>
</ul>
</div>
<div id="fecha" class="section level3">
<h3>Fecha</h3>
<p>El Royal Society Corpus viene anotado con fechas. Con estas fechas, podemos presentar preguntas históricas como “¿Cuándo se utilizaba la palabra <em>divers</em>?”</p>
<ul>
<li><code>RSC&gt; D = "divers";</code></li>
<li><code>RSC&gt; group D match text_year ;</code></li>
</ul>
<p>Y con algunos mandatos de unix, podemos organizar estos resultados por fecha:</p>
<ul>
<li><code>group D match text_year cut 10  &gt; "| tail -n +2  | sed 's/(none)/      /' | sort -nr";</code></li>
</ul>
<p>Para más información sobre el proceso de reenviar los resultados de una búsqueda a un archivo o una barra/pipa, se puede consultar la sección 3.2 del manual.</p>
</div>
</div>
<div id="tipos-y-casos" class="section level2">
<h2>Tipos y casos</h2>
<p>Esta distinción se refiere a la idea de que <strong>un caso (‘token’)</strong> es un ejemplo concreto; por otro lado, <strong>los tipos (‘types’)</strong> representan las categorías que incluyen estos ejemplos.</p>
<div id="la-misma-palabra" class="section level3">
<h3>La misma palabra</h3>
<p>Consideremos la siguiente oración “El ayuda a un montón de gente que no es conocida y se dedica a otra cosa”. En esta oración hay 17 palabras, donde dos de ellas son casos de la palabra <em>a</em>. En este caso, podemos decir que hay dos casos del mismo tipo. Cuando pedimos que el CQP nos cuente el número de observacioens de una palabra, lo que que nos da es el “token frequency” de este tipo.</p>
<ul>
<li><code>CDE&gt; MONTON = "montón";</code></li>
<li><code>CDE&gt; size MONTON;</code></li>
<li><code>57362</code></li>
</ul>
</div>
<div id="lemas" class="section level3">
<h3>Lemas</h3>
<p>A veces los tipos de palabras son demasiado específicos. Por ejemplo, si hacemos un estudio sobre el uso del verbo <em>ask</em>, no nos preocupa el tipo de letra (mayúscula vs. minúscula). Las propiedades relevantes son (i) su estatus como un verbo y (ii) y su raíz morfológica.</p>
<p>En el BNC, estas dos propiedades se combinan en un atributo posicional que se llama <code>lemma</code>. La clase léxica, en el sentido normal, se indica en el atributo headword <code>hw</code>. El atributo <code>lemma</code> incluye un símbolo que <a href="http://www.natcorp.ox.ac.uk/docs/URG/codes.html#klettpos">representa una etiqueta simplificada</a>. Esta etiqueta nos permite observar los resultados por caso y variación morfológica. El siguiente ejemplo utiliza el mandato <code>count</code> (<a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node15.html">sección 2.9 del manual</a>) permite que hagamos una distribución de frecuencias que es algo similar a lo que se produce con el mandato <code>group</code>.</p>
<ul>
<li><code>BNC&gt; ASK = [ lemma="ask_VERB" ];</code></li>
<li><code>BNC&gt; count ASK by word ;</code></li>
<li><code>30803   asked  [#19152-#49954]</code></li>
<li><code>17469   ask  [#1683-#19151]</code></li>
<li><code>5928    asking  [#49955-#55882]</code></li>
<li><code>1925    asks  [#55883-#57807]</code></li>
<li><code>1086    Ask  [#80-#1165]</code></li>
<li><code>402     Asked  [#1166-#1567]</code></li>
<li><code>105     Asking  [#1568-#1672]</code></li>
<li><code>56      ASK  [#0-#55]</code></li>
<li><code>13      ASKED  [#56-#68]</code></li>
<li><code>9       ASKS  [#71-#79]</code></li>
<li><code>9       Asks  [#1673-#1681]</code></li>
<li><code>2       ASKING  [#69-#70]</code></li>
<li><code>1       asKed  [#1682]</code></li>
<li><code>BNC&gt; size ASK;</code></li>
<li><code>57808</code></li>
</ul>
<p>El mandato <code>size</code> nos indica que la frecuencia de caso de este lema es 57808. Estas observaciones se distribuyen por trece tipos distintos, donde cada uno de ellos se muestra en una línea separada con <code>count</code>. Por lo tanto, la frecuencia de tipo (‘type frequency’) de este lema es 13.</p>
<p><strong>PREGUNTA:</strong> ¿Qué es la frecuencia de tipo del verbo <em>decir</em> en ANCORA?</p>
</div>
</div>
<div id="la-riqueza-léxica-y-ttr" class="section level2">
<h2>La riqueza léxica y TTR</h2>
<p>La cantidad de tipos en un corpus es necesariamente menos de (o a veces equivale a) la cantidad de casos. Sin embargo, ¿cómo debemos entender esta diferencia? La proporción entre los tipos y los casos–TTR (‘type-token-ratio’)–cuantifica el grado de diversidad de una selección de lengua. Es decir, cuanto más alta es el TTA, más diversa es el vocabulario. Si dividimos por el número de casos en el corpus, producimos una normalización por la cantidad de ‘’oportunidades’’ disponibles para observar una palabra nueva. Entonces, la TTR es una manera de cuantificar la riqueza léxica.</p>
<ul>
<li>TTR = <span class="math inline">\(\frac{n(tipos)}{n(casos)}\)</span></li>
</ul>
<p>Como un ejemplo, comparemos la riqueza léxia entre diferentes géneros de textos escritos. Acordáos que el mándato <code>size</code> nos produce frecuencias de casos:</p>
<ul>
<li><code>BNC&gt; FICTION = [ pos != "PU.*" ] :: match.text_genre = "W:fict.*"  ;</code></li>
<li><code>BNC&gt; size FICTION</code></li>
<li><code>16303411</code></li>
<li><code>BNC&gt; NEWS = [ pos != "PU.*" ] :: match.text_genre = "W:newsp:.*" ;</code></li>
<li><code>BNC&gt; size NEWS</code></li>
<li><code>9412245</code></li>
<li><code>BNC&gt; randomize 51;</code></li>
<li><code>BNC&gt; reduce FICTION to 9412245;</code></li>
<li><code>BNC&gt; size FICTION</code></li>
<li><code>9412245</code></li>
</ul>
<p>Con esta consulta, hemos excluído los casos de puntuación y hemos reducido la sección de FICTION a una selección aleatoria para que concuerde con el tamaño de la sub-sección NEWS (<a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node22.html">sección 3.6 del manual</a>). Este paso permite que los denominadores de las TTR tengan el mismo valor, 94122245.</p>
<p>Para obtener los numeradores, tenemos que contar los tipos. Una forma fácil de realizar este paso es contar la cantidad de líneas que se producen con los resultados de un mandato de CQP como <code>count</code> o <code>group</code>. Con el operador <code>&gt;</code> podemos “enviar” los resultados a un archivo mediante una “pipa” (‘pipe’) que contiene una función de unix como <code>wc</code>, lo cual nos cuenta las líneas (ya vimos este proceso el martes y se describe en <a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node18.html">la sección 3.2 del manual</a>). Se escribes <code>man wc</code> la próxima vez que te encuentras en el mensaje de unix, se puede apreder más sobre este programa. La etiqueta <code>%c</code> tiene el efecto de ignorar las distinciones entre letra mayúscula vs. minúscula (<a href="http://cwb.sourceforge.net/files/CQP_Tutorial/node8.html">sección 2.2 del manual</a>).</p>
<pre class="r"><code># BNC&gt; count FICTION by word %c &gt; &quot;| wc -l&quot;;
# 131476
# BNC&gt; count NEWS by word %c  &gt; &quot;| wc -l&quot;;
# 152648</code></pre>
<p>Ahora podemos calcular las TTR relevantes:</p>
<ul>
<li>TTR<sub>fiction</sub> = <span class="math inline">\(\frac{131476}{9412245}\)</span> = 0.013</li>
<li>TTR<sub>news</sub> = <span class="math inline">\(\frac{152648}{9412245}\)</span> = 0.16</li>
</ul>
<p>Según <a href="https://langsci-press.org/catalog/book/148">Stefanowitsch</a>, la TTR se puede interpretar como la probabilidad de encontrar un tipo nuevo, si seguimos encontrando nuevos tipos al mismo ritmo.</p>
</div>
<div id="los-afijos" class="section level2">
<h2>Los afijos</h2>
<p>Ahora podemos extender estas observaciones a la morfología. Stefanowitsch considera esta cuestión en el dominio de la morfología, especifícamente el uso del sufijo <em>-ly</em>. Si nuestro corpus consistiera de la siguiente oración de Shakespeare:</p>
<ul>
<li><code>CINNA: ...Am I a married man, or a bachelor? Then, to answer every man directly and briefly, wisely and truly: wisely I say, I am a bachelor.</code></li>
</ul>
<p>La frecuencia de casos del sufijo <em>-ly</em> sería 5 porque se observa en las palabras <em>directly</em>, <em>briefly</em>, <em>wisely</em>, <em>truly</em>, and <em>wisely</em>. Su frecuencia de tipo–es decir, el número de ejemplos de palabras específicas que tiene el sufijo <em>-ly</em>–es 4. Los dos ejemplos de <em>wisely</em> se consideran ejemplos del mismo tipo.</p>
<p>Podemos aplicar esta idea para entender los afijos <em>-icle</em> y <em>mini-</em>. Por ejemplo, un “denticle” es un diente pequeño, un “pellicle” es una membrana fina, y un “cubicle” es un seudo-oficina. Tal vez tenemos la intuición de que el sufijo <em>-icle</em> tiene una distribución más limitada que el prefijo <em>mini-</em>. También podemos cuantificar esta pregunta con el uso de la frecuencia de tipo.</p>
<div id="el-elemento--icle-como-un-sufijo" class="section level3">
<h3>El elemento <em>-icle</em> como un sufijo</h3>
<p>Empezemos con una búsqueda del sufijo <em>-icle</em> en casos singulares y plurales, sin considerar las variantes ortográficas:</p>
<pre class="r"><code># BNC&gt; [ word = &quot;.+icles?&quot; %c ] ;
# BNC&gt; size Last ;
# 20854
# BNC&gt; group Last match word &gt; &quot;icle-hits.txt&quot;;</code></pre>
<p>Después, utilicemos el programa <code>SCP</code> para transferir este archivo ‘icle-hits.txt’ a nuestra máquina local (página 13 del documento “Utilizing the UGA Corpus Server”). Después de limpiar la concordancia, los resultados salen en la Tabla 1:</p>
<ul>
<li>Tabla 1: ejemplos de los tipos de <em>-icle</em> (casos de errores ortográficos se han quitado)</li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Palabra</th>
<th align="left">Palabra</th>
<th align="left">Palabra</th>
<th align="left">Palabra</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">article 9515</td>
<td align="left">cronicles 1</td>
<td align="left">fascicle 8</td>
<td align="left">pedicle 1</td>
<td align="left">testicle 128</td>
</tr>
<tr class="even">
<td align="left">astricles 2</td>
<td align="left">cubicle 233</td>
<td align="left">follicle 69</td>
<td align="left">pellicle 1</td>
<td align="left">tunicles 1</td>
</tr>
<tr class="odd">
<td align="left">auricles 1</td>
<td align="left">curricle 5</td>
<td align="left">funicle 3</td>
<td align="left">pericle 70</td>
<td align="left">uncanonicles 1</td>
</tr>
<tr class="even">
<td align="left">barnicles 2</td>
<td align="left">cuticle 131</td>
<td align="left">icicle 56</td>
<td align="left">pollicle 1</td>
<td align="left">vehicle 7235</td>
</tr>
<tr class="odd">
<td align="left">canticle 24</td>
<td align="left">denticles 1</td>
<td align="left">jellicle 3</td>
<td align="left">popsicle 3</td>
<td align="left">ventricle 40</td>
</tr>
<tr class="even">
<td align="left">chicles 3</td>
<td align="left">dicle 1</td>
<td align="left">mesocuticle 1</td>
<td align="left">procuticle 8</td>
<td align="left">versicles 2</td>
</tr>
<tr class="odd">
<td align="left">chronicle 639</td>
<td align="left">endocuticle 4</td>
<td align="left">ossicles 3</td>
<td align="left">radicle 2</td>
<td align="left">vesicle 144</td>
</tr>
<tr class="even">
<td align="left">clavicle 15</td>
<td align="left">epicuticle 9</td>
<td align="left">panicles 5</td>
<td align="left">runnicles 4</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">conventicle 22</td>
<td align="left">exocuticle 5</td>
<td align="left">particle 2447</td>
<td align="left">subcuticle 1</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Observamos 43 tipos y 20850 casos. De hecho, podemos mejorar bastante los resultados con el uso de un “stoplist” en CQP. De esta forma, ignoramos los casos que no buscamos.</p>
</div>
<div id="el-elemento-mini--como-un-prefijo" class="section level3">
<h3>El elemento <em>mini-</em> como un prefijo</h3>
<pre class="r"><code># BNC&gt; define $stopword &lt; &quot;not-instances-of-mini.txt&quot; ;
# BNC&gt; MINI1 = [ word=&quot;mini(-)?.+&quot; %c &amp; word != RE($stopword) %c] ;
# BNC&gt; size MINI1
# 1840
# BNC&gt; count MINI1 by word %c &gt; &quot;| wc -l&quot;;
# 510</code></pre>
<p>En esta consulta, estamos eliminando las palabras que aparecen en nuestra lista de palabras. El operator <code>RE()</code> del CPQ interpreta esta lista como una lista de expresiones regulures en vez de ser una simple grupo de palabras. La lista representada en “not-instances-of-mini.txt” se encuentra en la Tabla 2:</p>
<table>
<thead>
<tr class="header">
<th align="left">Palabra</th>
<th align="left">Palabra</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">minimi[sz].*</td>
<td align="left">miniver</td>
</tr>
<tr class="even">
<td align="left">minim(al? <span class="math inline">\(|\)</span> um <span class="math inline">\(|\)</span> i[sz]e)(ist <span class="math inline">\(|\)</span> ly <span class="math inline">\(|\)</span> ism)?.*</td>
<td align="left">miniate</td>
</tr>
<tr class="odd">
<td align="left">mininal</td>
<td align="left">miniutes</td>
</tr>
<tr class="even">
<td align="left">miniatur.*</td>
<td align="left">minim.*</td>
</tr>
<tr class="odd">
<td align="left">minist[eéè]?r.*</td>
<td align="left">mininum</td>
</tr>
<tr class="even">
<td align="left">min(e</td>
<td align="left">ing).*</td>
</tr>
<tr class="odd">
<td align="left">minimum</td>
<td align="left">minite?</td>
</tr>
<tr class="even">
<td align="left">minions?</td>
<td align="left">miniuscula</td>
</tr>
<tr class="odd">
<td align="left">minims?</td>
<td align="left">miniutes</td>
</tr>
<tr class="even">
<td align="left">miniscule</td>
<td align="left">minimse</td>
</tr>
</tbody>
</table>
</div>
<div id="downsampling" class="section level3">
<h3>Downsampling</h3>
<p>Los denominadores en el último ejempo no son equivalentes. Según Brezina (§ 2.6), los textos más largos presentan la oportunidad de reciclar la misma forma. ¿Es que el sufijo <em>-cle</em> combine con las mismas bases o es que las mismas mismas se observen varias veces? Lo que podemos hacer es producir un “downsample”–es decir, un conjunto aleatorio de observaciones de <em>-icle</em> que es igual de tamaño al número de observaciones de <em>mini</em>.</p>
<pre class="r"><code># BNC&gt; randomize 37;
# BNC&gt; ICLE = [ word = &quot;.+icles?&quot; %c ] ;
# BNC&gt; reduce ICLE to 1840 ;
# BNC&gt; group ICLE match word &gt; &quot;icle1840.txt&quot;;</code></pre>
<p>Ahora podemos limpiar el archivo “icle1840.txt” y determinar que solo hay 17 diferentes tipos. Comparemos las TTR de <em>-icle</em> y de <em>mini-</em>.</p>
<ul>
<li>TTR<sub>icle</sub> = <span class="math inline">\(\frac{17}{1840}\)</span> = 0.009</li>
<li>TTR<sub>mini</sub> = <span class="math inline">\(\frac{510}{1840}\)</span> = 0.277</li>
</ul>
<p>Se nota que la TTR<sub>icle</sub> es mucho menos de la TTR<sub>mini</sub>. Es decir, la asimetría entre las frecuencias de <em>-icle</em> y <em>mini-</em> es consistent con el hecho de que el segundo sea más “importante” en el lexicón del inglés, tal vez por cuestión de que se puede combinar más libremente con otras palabras. Según Stefanowitsch, es importante notar que todavía no hemos hecho ningún argumento estadístico.</p>
</div>
<div id="tarea" class="section level3">
<h3>Tarea</h3>
<p>Con esta tarea exploremos la distribución de los sufijos <em>-azo(s)/-aza(s)</em> y <em>-ito(s)/-ita(s)</em> en el corpus de ANCORA.</p>
<p><strong>1^a Parte</strong> Realiza unas búsquedas de las palabras terminadas en los sufijos <em>-azo(s)/-aza(s)</em> y <em>-ito(s)/-ita(s)</em>. ¿Cuántos casos se encuentran?</p>
<p><strong>2^a Parte</strong> Produce las TTR de estos dos elementos. ¡Cuidado! Hay que eliminar las palabas que no tengan estos elementos como prefijos (p.e. <em>necesito</em>). ¿Cómo se compara el uso de <em>-azo(s)/-aza(s)</em> con <em>-ito(s)/-ita(s)</em> en este corpus?</p>
</div>
</div>
</div>
<div id="a-semana-4" class="section level1">
<h1>6a Semana</h1>
<div id="la-ley-de-zipf" class="section level2">
<h2>La ley de Zipf</h2>
<p>: Con las búsquedas que hemos realizado hasta ahora, hemos notado un patrón interesante (¿sospechoso?). Las expresiones bien representadas son muy muy frecuentes. Pero, cuando vemos las otras partes de la lista, se observa que entramos rápidamente en el territorio de los <em>hapax legomena</em><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> Por ejemplo, si volvemos a la consulta que ya hicimos sobre las costrucciones verbales frasales, se observa que, si aun se excluyen los casos de “be out” and “turned out that”, las estructuras como “go out”, “look out” y “get out” son <em>mucho</em> más frecuentes que las demás. ¿Cómo se explica esta distribución?</p>
<pre class="r"><code># DICKENS&gt; PhrasalV = @[ pos=&quot;V.*&quot; &amp; lemma != &quot;be&quot; ] [ word=&quot;out&quot; ] [ word != &quot;that&quot;];
# DICKENS&gt; group PhrasalV target lemma cut 100 ;</code></pre>
<div id="observamos-todas-las-palabras" class="section level3">
<h3>Observamos todas las palabras</h3>
<p>Vamos a cambiar de corpus y ver si esta distribución se aplica cuando consideramos todas las palabras (menos la puntuación) a la vez:</p>
<pre class="r"><code># BROWN&gt; NONPUNCT = [ pos != &quot;(\.|\(|\)|\*|--|\,|:|``|&#39;&#39;|&#39;)(-(HL|TL|NC)){0,2}&quot; ] ;
# BROWN&gt; count NONPUNCT by word %c ;</code></pre>
<p>Estos resultados nos muestran que las palabras funcionales como “the” y “of” son las más frecuentes en la distribución de frecuencias. Sin embargo, ¡<strong>más de la mitad</strong> de los tipos solo se observan una vez! Este efecto se puede observar por contar las líneas individuales el output de <code>count</code> con el mandato de unix que vimos la semana pasada (para más información sobre <code>egrep</code>, se debe consultar la sección 2.3 del capítulo de Lu 2014).</p>
<pre class="r"><code># BROWN&gt; count NONPUNCT by word %c &gt; &quot;| egrep &#39;^1[[:blank:]]&#39; | wc -l&quot; ;
# 22012
# BROWN&gt; count NONPUNCT by word %c &gt; &quot;|  wc -l&quot; ;
# 49804</code></pre>
<p>Esta situación, donde una cantidad pequeña de expresiones son <strong>super</strong> frecuentes y las demás tienen una frecuencia que se acerca a 1, se llama <strong>la Ley de Zipf</strong>.</p>
</div>
</div>
<div id="la-ley-de-zipf-1" class="section level2">
<h2>La “ley” de Zipf</h2>
<p>La ley de Zipf es una “regularidad empírica”, motivado por George Kingsley Zipf en su libro del año 1935 con el título, <em>The Psycho-biology of language</em>. La “regularidad” se puede describir con el argument que la frecuencia <span class="math inline">\(f\)</span> de una palabra es inversamente proporcional a su rango <span class="math inline">\(r\)</span> en una lista (ordenada) de palabras frecuentes.La ecuación que presenta Brezina en la página 44 representa esta idea. Consideremos esta situación con el corpus de Brown:</p>
<table>
<thead>
<tr class="header">
<th align="left">palabra</th>
<th align="left">frecuencia</th>
<th align="left">rango</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">the</td>
<td align="left">69971</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">of</td>
<td align="left">36412</td>
<td align="left">2</td>
</tr>
<tr class="odd">
<td align="left">and</td>
<td align="left">28853</td>
<td align="left">3</td>
</tr>
<tr class="even">
<td align="left">to</td>
<td align="left">26158</td>
<td align="left">4</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="left">23195</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">in</td>
<td align="left">21337</td>
<td align="left">6</td>
</tr>
<tr class="odd">
<td align="left">that</td>
<td align="left">10594</td>
<td align="left">7</td>
</tr>
<tr class="even">
<td align="left">is</td>
<td align="left">10109</td>
<td align="left">8</td>
</tr>
<tr class="odd">
<td align="left">was</td>
<td align="left">9815</td>
<td align="left">9</td>
</tr>
<tr class="even">
<td align="left">he</td>
<td align="left">9548</td>
<td align="left">10</td>
</tr>
<tr class="odd">
<td align="left">i</td>
<td align="left">5164</td>
<td align="left">20</td>
</tr>
<tr class="even">
<td align="left">which</td>
<td align="left">3561</td>
<td align="left">30</td>
</tr>
<tr class="odd">
<td align="left">we</td>
<td align="left">2652</td>
<td align="left">40</td>
</tr>
<tr class="even">
<td align="left">out</td>
<td align="left">2097</td>
<td align="left">50</td>
</tr>
<tr class="odd">
<td align="left">can</td>
<td align="left">1772</td>
<td align="left">60</td>
</tr>
<tr class="even">
<td align="left">then</td>
<td align="left">1380</td>
<td align="left">70</td>
</tr>
<tr class="odd">
<td align="left">man</td>
<td align="left">1207</td>
<td align="left">80</td>
</tr>
<tr class="even">
<td align="left">must</td>
<td align="left">1013</td>
<td align="left">90</td>
</tr>
<tr class="odd">
<td align="left">down</td>
<td align="left">895</td>
<td align="left">100</td>
</tr>
<tr class="even">
<td align="left">little</td>
<td align="left">831</td>
<td align="left">110</td>
</tr>
<tr class="odd">
<td align="left">work</td>
<td align="left">762</td>
<td align="left">120</td>
</tr>
<tr class="even">
<td align="left">day</td>
<td align="left">687</td>
<td align="left">130</td>
</tr>
<tr class="odd">
<td align="left">year</td>
<td align="left">658</td>
<td align="left">140</td>
</tr>
<tr class="even">
<td align="left">three</td>
<td align="left">610</td>
<td align="left">150</td>
</tr>
</tbody>
</table>
<p>Este argumento sobre la proporcionalidad inversa significa que las proporciones de los rangos deben ser proporciones de las frecuencias: es decir, la 50a palabra más común debe tener una frecuencia que es, más o menos, tres veces más que la 150a palabra más común. En esta tabla, 2097 (la frecuencia de la 50a palabra-“out”) sí tiene esta propiedad: <span class="math inline">\(3*610=1830\)</span>, donde <span class="math inline">\(f_{150}=610\)</span>. La forma típica de visualizar esta distribución es con un cuadro logorítmico, donde se calcula el logoritmo de los dos lados:</p>
<div class="figure">
<img src="images/Logorithm.png" alt="" />
<p class="caption">El cáluco de los logoritmos</p>
</div>
<p>El paso del (1) a (2) nos produce un elemento constante de proporcionalidad, <code>h</code>. El paso (3) sigue del paso (2) mediante la ley de los logaritmos. Este elemento constante <code>h</code> produce la tendencia decresciente que se observa con la ley de Zipf.</p>
<p>Las distribuciones de Zipf (“Zipfian”) son muy comunes en la lengua natural, para todos tipos de expresiones lingüísticas y con escalas de diferentes niveles.</p>
<p><strong>Ejercicio</strong>: Completemos la tabla en la pregunta 5 de Brezina (página 63).</p>
<div id="la-visualización" class="section level3">
<h3>La visualización</h3>
<p>Cuando se producen distribuciones de frecuencias con el CQP, las podemos compartir con otros programs. Por ejemplo, podemos utilizar <a href="https://www.r-project.org/">el programa estadística y gráfica R</a>. Para poder sacar una distibución de frecuencia con el CQP, podeos utilizar un mandato de unix que pertenece a la familia <code>awk</code> (sección 2.3.5 de Lu 2014). En el siguiente ejemplo, <code>awk</code> se utiliza para extraer la primera columna (el “attestation count”) y la columna 2 (la palabra). La tercera y la última columna que produce el mandato <code>count</code> son los que se utilizan para producir la concordancia de KWIC y, por lo tanto, no se tienen que guardar.</p>
<pre class="r"><code># BROWN&gt; count NONPUNCT by word %c &gt; &quot;| awk &#39;{print $1,$2}&#39; &gt; brown-nonpunct.cnt&quot; ;</code></pre>
<p>El signo <code>&gt;</code> es lo que se llama un “output redirection operator” del CPQ. El signo <code>|</code> es otro símbolo que se utiliza dentro de las comillas que signifca que los resultados de <code>count</code> serán eviandos (‘piped’) a otro mandato, en este caso <code>awk</code>. Finalmente, el signo <code>&gt;</code> dentro de las comillas es otro operador de redistribución, pero en este caso queremos tomar los resultados de <code>awk</code> y producir un archivo con un nombre específico–<code>brown-nonpunct.cnt</code>. Con este archivo, ahora podemos utilizar SCP para transferir el archivo a nuestro laptop:</p>
<pre class="r"><code># laptop% scp ugaMyID@corpus.uga.edu:brown-nonpunct.cnt .</code></pre>
<p>Lo que hace el mandato de scp es extraer el archivo <code>brown-nonpunct</code> del servidor y guardarlo a un espacio local, indicador con el punto. Ahora podemos utilizar el programa R para producir un gráfico:</p>
<pre class="r"><code># library(ggplot2)
# brown &lt;- read.table(&quot;brown-nonpunct.cnt&quot;,header=F,colClasses=c(&quot;integer&quot;,&quot;character&quot;),sep=&quot; &quot;))
# names(brown) &lt;- c(&quot;attestations&quot;,&quot;word&quot;)
# quickplot(1:100,brown$attestations[1:100],main=&quot;Brown corpus&quot;,xlab=&quot;rank&quot;,ylab=&quot;attestations&quot;,log=&quot;xy&quot;,geom=c(&quot;point&quot;,&quot;smooth&quot;),method=&quot;lm&quot;,se=F)</code></pre>
<div class="figure">
<img src="images/Zipf1.png" alt="" />
<p class="caption">La distribución Zipf de todas las palabras del corpus Brown</p>
</div>
</div>
<div id="algunas-observaciones-importantes" class="section level3">
<h3>Algunas observaciones importantes</h3>
<ol style="list-style-type: decimal">
<li>La ley de Zipf es la norma. Se espera observarla en todos los niveles del análisis lingüístico.</li>
<li>Por consiguiente, nunca hay datos suficientes.</li>
<li>Si un elemento (o una estructura) no aparece en el corpus, **NO* significa que no sea parte de la lengua.</li>
</ol>
</div>
</div>
<div id="tarea-1" class="section level2">
<h2>Tarea</h2>
<p>Para el próximo jueves, vamos a calcular la distribución Zipfiana del ANCORA siguiendo los mismos pasos que acabamos de realizar con Brown.</p>
</div>
</div>
<div id="a-semana-5" class="section level1">
<h1>7a Semana</h1>
<p><strong>El uso de PolmineR:</strong> El paquate de R preparado pro <a href="https://www.uni-due.de/politik/blaette_forschung.php">Andreas Blätte</a> facilita el proceso de producir gráficas y realizar el análisis estadístico con los resultados de nuestro análisis de corpus. En esta sección del curso, introducimos el paquete <code>polmineR</code>, explicamos su integración con nuestro servidor, y describimos las funcionalidades principales que se desciben en <a href="https://cran.r-project.org/web/packages/polmineR/vignettes/vignette.html">el polmineR vignette</a>.</p>
<div id="los-requisitos" class="section level2">
<h2>Los requisitos</h2>
<ol style="list-style-type: decimal">
<li>Primero, hay que instalar <a href="https://cran.r-project.org/doc/manuals/r-release/R-FAQ.html#What-is-R_003f">el sistema estadístico y grafíco de R</a>. También, recomiendo que también se instale <a href="https://rstudio.com/">el programa de RStudio</a>.</li>
<li>Abre <a href="https://eits.uga.edu/access_and_security/infosec/tools/vpn/">el VPN</a>. Después, tiene que ajuntar las dos unidades de disco que se exportan del servidor de corpus de UGA. Este proceso está descrito en los siguientes documentos: para <a href="https://uga.view.usg.edu/d2l/le/content/2064782/viewContent/32252896/View">macOS</a> y <a href="https://uga.view.usg.edu/d2l/le/content/2064782/viewContent/32252907/View">Windows</a>.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></li>
<li>Verifica que el paquete <code>polmineR</code> se ha estalado. En el R console, escribe o <code>install.packages("polmineR",repos="https://polmine.github.io/drat")</code> para macOS o<code>install.packages("polmineR",repos="https://polmine.github.io/drat",type="win.binary")</code> para Windows. Solo hay que hacer este proceso una vez.’<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></li>
<li>Según esta configuración, tu computadora es la que produce las consultas y calcula los resultados. El servidor de corpus de UGA sirve como el servidor de archivo para los corpus.</li>
</ol>
</div>
<div id="a-probarlo" class="section level2">
<h2>¡A probarlo!</h2>
<p>Para utilizar los corpus dentro del ambiente de R, tenemos que indicar el “registry” apropiado con el proceso de establecar un “environment variable”. Hay dos registros seperados: uno para macOS y otro para Windows. Se puede establecer estas variables con R mediante el mandato <code>Sys.setenv</code>. El mandato <code>getenv</code> permite que verifiquemos que hemos establecido correctamente los registros. Los materiales después de la marca de hash es un comento; es un tipo de documentación, no un mandato.</p>
<pre class="r"><code>#&gt; Sys.setenv(&quot;CORPUS_REGISTRY&quot; = &quot;/Volumes/cwb_registry/mac_registry&quot;) # or &quot;R:/windows_registry&quot; if you are running Windows
#&gt; Sys.getenv(&quot;CORPUS_REGISTRY&quot;) # check that it was successfully set</code></pre>
<p>Cuando esté listo el <code>CORPUS_REGISTRY</code> para el disco apropiado, ya estamos listos para abrir el paquete de <code>polmineR</code>. <a href="https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Packages">El manual de R explica el proceso de trabajar con los paquetes</a>.</p>
<pre class="r"><code>#&gt; library(polmineR)</code></pre>
<p>Si funcionó bien, podemos pedir que nos produzca una lista de los corpus disponibles:</p>
<pre class="r"><code>#&gt; corpus()</code></pre>
</div>
<div id="las-concordancias" class="section level2">
<h2>Las concordancias</h2>
<p>El mandato de <code>kwic</code> produce una concordancia de ‘keyword-in-context’. El primero argumento es el nombre del corpus, y el segundo es la búsqueda. El programa R reconoce los argumentos de una fución o por su posición o por la sintáxis <code>name=arg</code>. Por eso, los dos siguientes mandatos son equivalentes.</p>
<pre class="r"><code>#&gt; kwic(&quot;DICKENS&quot;,&quot;door-nail&quot;)
#&gt; kwic(&quot;DICKENS&quot;,query=&quot;door-nail&quot;)</code></pre>
<p>Debe aparecer una ventana “pop-up” con con algunos controles para explorar los resultados. Para consultar la documentación de <code>kwic</code> o cualquier otra función de R, podemos utilizar el mandato <code>?kwic</code> o <code>help(kwic)</code> al mensaje de R (<code>&gt;</code>).</p>
</div>
<div id="contar-casos" class="section level2">
<h2>Contar casos</h2>
<p>El mandato <code>count</code> calcula las frecuencias de las palabras. Su resultado es un tipo de “data frame”. Se debe consultar la subsección sobre DATA FRAMEs en la introducción al R preparada por Jonathan Jones. Si la búsqueda es una sola palabra, este Data Frame tendrá una sola fila, como se demuestra con los siguientes ejemplos:</p>
<pre class="r"><code>#&gt; count(&quot;DICKENS&quot;,query=&quot;nail&quot;)
#&gt; count(&quot;DICKENS&quot;,query=&quot;nails&quot;)
#&gt; count(&quot;DICKENS&quot;,query=&#39;&quot;nails?&quot;&#39;,cqp=TRUE)
#&gt; count(&quot;DICKENS&quot;,query=&#39; [word=&quot;nails?&quot;] &#39;,cqp=T)</code></pre>
<p>Las primeras consultas solo contienen palabras. La tercera contiene una expresión regular (<code>?</code>) que nos busca la forma singular “nail” y plural “nails”. Podemos pedirle a <code>polmineR</code> que reconozca las consultas del tipo <code>CQP</code> con el argumento <code>cqp=T</code> (donde <code>T</code> es un elemento constante que signific TRUE en R). Incluímos la consulta con comillas simples porque la consulta misma se indica con comillas. La cuarta consulta es otra versión equivalente que hace explícita el requisito de que los atributos de las palabras tienen que concordar con la expresión regular <code>nails?</code>. Observemos que 73=30+43; la única fila del Data Frame que resulta de la búsqueda que contiene todos las variantes de las formas singulares y plurales.</p>
<p>Además, podemos especificar que queremos varias filas a la vez mediante el uso de la función <code>c()</code>.</p>
<pre class="r"><code>#&gt; ail&lt;-count(&quot;DICKENS&quot;,query=c(&quot;nail&quot;,&quot;nails&quot;))</code></pre>
<p>El resultado de este tipo de múltiple consulta se puede asignar a una variable como <code>nail</code> con la flechita. Cuando asignmamos el resultado de una función a una variable, no se produce un output. El output se puede exhibir por escribir el nombre de los resultados, en este caso <code>nail</code>.</p>
<p>Si seguimos con este exemplo, veremos que el elemento <code>nail$query=="nails"</code> es un predicado que, para la segunda fila del data frame, es verdad pero no para el segundo. Esta especificación para las files tiene el nombre de un <a href="https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Index-vectors">“index vector”</a>. Abajo, se nota que el index vector recibe el nombre de <code>i</code> mediante el proceso de la asignación. Después, cuando escribimos <code>i</code>, el R produce el value de esta variable, lo cual en este caso es un vector de dos valores de veracidad (“truth values”).</p>
<pre class="r"><code>#&gt; i  &lt;- nail$query==&quot;nails&quot;
#&gt; i</code></pre>
<p>Si utilizamos el index vector dentro de los corchetes después del nombre de un data frame produce el efecto de hacer un subconjunto de los datos que satisfacen este predicado.</p>
<pre class="r"><code>#&gt; nail[i]</code></pre>
<p>Así solo nos queda una fila que contiene las formas plurales.</p>
</div>
<div id="la-dispersión" class="section level2">
<h2>La dispersión</h2>
<p>Algunas formas se localizan de manera concentrada en una parte del corpus, mientras que otros se observan mediante todo el corpus. Este fenómeno, descrito por Brezina (sección 2.4) como "The Whelk Problem (homenaje a Adam Kilgarriff), se ha designado como la dispersión.</p>
<div id="un-repaso-con-el-royal-society-corpus" class="section level3">
<h3>Un repaso con el Royal Society Corpus</h3>
<p>Hace tiempo estudiamos diferentes formas de la palabra “divers” con el Royal Society Corpus. Los detalles de este corpus, y cualquier otro corpus en el servidor, se pueden recuperar desde el mensaje de R. Solo formamos un “corpus object” con el mandato <code>corpus</code>. Entonces, el objecto que resulta sirve como punto de referencia para diferentes tipos de información–p.e. el tamaño, el origen, y los atributos.</p>
<pre class="r"><code>#&gt; rsc  &lt;-  corpus(&quot;RSC&quot;)
#&gt; show_info(rsc)
#&gt; s_attributes(rsc)</code></pre>
<p>Con el atributo-s de <code>text_year</code>, podemos verificar para ver cuáles eran los años cuando la palabra <code>divers</code> se observó más o menos. Utilizemos el mandato <code>dispersion</code> y formemos una tabla con la forma y el año. La función <code>head</code> de R nos da la posibilidad de ver solo unas filas (o columnas) a de un data frame más extendido (en este caso con 210 filas).</p>
<pre class="r"><code>#&gt; divers  &lt;- dispersion(&quot;RSC&quot;,query=&#39;divers&#39;,s_attribute=&quot;text_year&quot;)
#&gt; head(divers)</code></pre>
<p>Después, podemos producir una gráfica de barra directamente con estos resultados:</p>
<pre class="r"><code>#&gt; barplot(height = divers$count, names.arg = divers$text_year, las = 2)</code></pre>
</div>
<div id="wuthering-heights" class="section level3">
<h3>Wuthering Heights</h3>
<p>¿Cómo funciona <code>dispersion</code>? Podemos construir nuestra propia función de <code>dispersion</code> y estudiar la mención de personajes en la literatura inglesa.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p>Primero, tenemos que crear un vector de posiciones de corpus en Wuthering Heights. Este poceso puede ser afectado por la repetición del valor disparatado NA (‘Not Applicable’) lo cual es muy frecuente en este corpus.</p>
<p>Después, utilzamos la función de polmineR <code>cpos</code> para revelar las posiciones de corpus que concuerdan con el nombre propio “Heathcliff”. Si utilizamos el mandato <code>?cpos</code>, podemos consultar la documentación para verificar que el resultado de <code>cpos</code> es una matrix de dos columnas donde la primera columna contiene las posiciones initiales de la consulta y la segunda contiene las posiciones finales. Como el elemento “Heathcliff” es solo una palabara, estos números son iguales, así que elegimos arbitráriabmente la primera columna mediante el uso de <a href="https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Array-indexing">la notación comma-1</a>.</p>
<p>Esta columna de posiciones de corpus sirve como un tipo de index vector. Si ponemos este vector dentro de corchetes a la mano izquierda de la flechita de asignación, podemos definir estas posiciones al valor 1 y dejamos que las demás posiciones de corpus donde el nombre “Heathcliff” no se menciona con el valor NA. Este vector ya revisado <code>w_count</code> sirve como un argumento apropiado para el mandato gráfico básico de R, <code>plot</code>.</p>
<pre class="r"><code># everything is NA
#&gt; w_count &lt;- rep(NA,times=size(&quot;WUTHERING&quot;))
 # until Healthcliff is mentioned
#&gt; where_he_is_mentioned  &lt;- cpos(&quot;WUTHERING&quot;,&quot;Heathcliff&quot;)[,1]
 # set all of those corpus positions to the value 1
#&gt; w_count[where_he_is_mentioned] &lt;- 1
 #Your plot may also appear a lot taller (or thicker) than the one seen here.
#&gt; plot(w_count,main=&quot;Gráfica de dispersión de `Healthcliff` en Wuthering Heights&quot;,xlab=&quot;Duración de la Novela&quot;,ylab=&quot;Healthcliff&quot;,type=&quot;h&quot;,ylim=c(0,1),yaxt=&#39;n&#39;)</code></pre>
<p>Notemos que Heathcliff aparece mediante toda la novela, aunque el carácter Edgar se muere en la mitad de la historia.</p>
<pre class="r"><code># everything is NA
#&gt; w_count2 &lt;- rep(NA,times=size(&quot;WUTHERING&quot;))
 # until Edgar is mentioned
#&gt; where_edgar_is_mentioned  &lt;- cpos(&quot;WUTHERING&quot;,&quot;Edgar&quot;)[,1]
 # set all of those corpus positions to the value 1
#&gt; w_count2[where_edgar_is_mentioned] &lt;- 1
 #Your plot may also appear a lot taller (or thicker) than the one seen here.
#&gt; plot(w_count2,main=&quot;Gráfica de dispersión de `Edgar` en Wuthering Heights&quot;,xlab=&quot;Duración de la Novela&quot;,ylab=&quot;Edgar&quot;,type=&quot;h&quot;,ylim=c(0,1),yaxt=&#39;n&#39;)</code></pre>
</div>
<div id="más-sobre-la-dispersión" class="section level3">
<h3>Más sobre la dispersión</h3>
<p>Ahora consideremos la palabra “breakfast” en el corpus de BNC. ¿Cómo son distintas las dispersiones de esta polabra en este corpus. Primero, se nota que la palabra “breakfast” se observa con 3751 casos.</p>
<pre class="r"><code>#&gt; count(&quot;BNC&quot;,query=&quot;breakfast&quot;)</code></pre>
<p>Después, apliquemos el mandato de <code>dispersion</code> para identificar los textos donde aparece esta palabra. Notemos que muchos de los resultados son nulos:</p>
<pre class="r"><code>#&gt; bkf_by_text  &lt;- dispersion(&quot;BNC&quot;,&quot;breakfast&quot;,s_attribute=&quot;text_id&quot;)
#&gt; head(bkf_by_text)</code></pre>
<p>Formemos un vector de índice que nos da las observaciones (los textos) que contienen la palabra “breakfast”. Podemos contar los números de textos, tanto el total como los que contienen la palabra “breakfast”, por introducir las funciones de <code>length</code> y <code>unique con la notación</code>$<code>para referir al</code>text_id` de cada data frame (ver la discusión de <a href="https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Lists">named list components en el R Manual</a>).</p>
<pre class="r"><code>#&gt; texts_where_bkfast_is_mentioned  &lt;- bkf_by_text[bkf_by_text$count &gt; 0]
#&gt; total_number_texts  &lt;-  length(unique(bkf_by_text$text_id))
#&gt; number_bkfast_texts  &lt;- length(unique(texts_where_bkfast_is_mentioned$text_id))
#&gt; (number_bkfast_texts/total_number_texts)*100
#[1] 25.58656</code></pre>
<p>El resultado es el “rango”, lo que describe Brezina (sección 2.4) como una medida básica de la dispersión. La interpretación es que la palabra “breakfast” aparece en 25% de los textos del BNC. Con esta misma técnica, podemos determinar el “rango” de de la palabra “corpus”. Esta palabra exhibe un rango más bajo y solo aparece en 3% de los textos del BNC. La interpretación es (o puede ser) que el análisis de corpus no es de interés general, mientras que el desayuno sí.</p>
</div>
</div>
</div>
<div id="a-semana-6" class="section level1">
<h1>8a Semana</h1>
<div id="los-intensificadores" class="section level2">
<h2>Los intensificadores</h2>
<p>La selección de un intensificador (p.e. <em>very</em> y <em>really</em> en inglés o <em>muy</em> y <em>bien</em> en español) es una variable bastante interesante. Consideremos la distribución de la palabra “lovely” como intensificador. ¿Es más común esta palabra con los hombres o las mujeres? ¿Qué podemos decir si comparamos esta palabra con la palabra “ace”, que también se puede utilizar para intensificar de manera positiva? ¿Habrá una <strong>contingencia</strong> entre el género del/de la escritor(a) y su uso de utilizar una de estas expresiones?</p>
<p>Antes de seguir, verifiquemos que todo está preparado para poder trabajar directamente con R, como se describe en los SMB Setup Guides de macOS y de Windows. También, tenemos que poner la variable ambiental de CORPUS_REGISTRY y inicializar el paquete de <code>polmineR</code>.</p>
<p>Primero, foremos dos data frames para cada expresión, con la clasificación adicional de <code>text_author_sex</code>.</p>
<pre class="r"><code># lovely &lt;- dispersion(&quot;BNC&quot;, query = &quot;lovely&quot;, s_attribute = &quot;text_author_sex&quot;)
# ace &lt;- dispersion(&quot;BNC&quot;, query = &quot;ace&quot;, s_attribute = &quot;text_author_sex&quot;)</code></pre>
<p>Ahora, podemos representar estas cantidades con una tabla 2x2. En esta tabla, las filas representan la expresión lingüística y las columnas representan los dos géneros en el corpus, “male” y “female”.</p>
<p><strong>Tabla 1:</strong> Tabla de contingencia entre <em>lovely</em> y <em>ace</em> por género del autor</p>
<table>
<thead>
<tr class="header">
<th align="left">palabra</th>
<th align="left">male</th>
<th align="left">female</th>
<th align="left">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">lovely</td>
<td align="left">751</td>
<td align="left">1337</td>
<td align="left">2088</td>
</tr>
<tr class="even">
<td align="left">ace</td>
<td align="left">48</td>
<td align="left">19</td>
<td align="left">67</td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="left">799</td>
<td align="left">1356</td>
<td align="left">2155</td>
</tr>
</tbody>
</table>
<p>Dentro de R, este proceso es bastante fácil:</p>
<pre class="r"><code>#&gt; four_counts  &lt;- c(lovely[text_author_sex==&quot;male&quot;]$count,ace[text_author_sex==&quot;male&quot;]$count,lovely[text_author_sex==&quot;female&quot;]$count,ace[text_author_sex==&quot;female&quot;]$count)
#&gt; T &lt;- matrix(four_counts,ncol=2)
  # add names for the table&#39;s columns and rows
#&gt; rownames(T) &lt;- c(&quot;lovely&quot;, &quot;ace&quot;)
#&gt; colnames(T) &lt;- c(&quot;male&quot;, &quot;female&quot;)
#&gt; T
#       male female
#lovely  751   1337
#ace      48     19</code></pre>
<p>También podemos visualizar estos datos con una gráfica que se llama un “mosaic plot” con el paquete de <code>vcd</code>. Esta visualización muestra claramente que existe dos desequilibrios: el número mucho mayor de casos de “lovely” y una diferencia entre los hombres y las mujeres con respeto al uso de estas palabras.</p>
<p><img src="images/MosaicPlot.png" alt="Figura 1: Mosaic Plot (Brezina, pag. 109)" /> Observamos con la Tabla 1 los número que se escriben en las márgenes. Estos representan los totales para las filas y para las columnas. Podemos pedir que R nos los calcule con la función <code>marginSum</code>. Indicamos 1 o 2 para pedir las sumas de las filas o las columnas, respectivamente.</p>
<pre class="r"><code>#&gt; marginSums(T,1)
#lovely    ace 
#  2088     67 
#&gt; marginSums(T,2)
#  male female 
#   799   1356</code></pre>
<p>El elemento marginal en la esquina derecha y abajo representa la cantidad total de las observaciones. Si dividimos cada celda por este número, se producen una seria de proporciones. Podemos producir estas proporciones en R con el mandato <code>prop.table</code>.</p>
<pre class="r"><code>#&gt; prop.table(T)
#             male      female
#lovely 0.34849188 0.620417633
#ace    0.02227378 0.008816705</code></pre>
</div>
<div id="otra-vez-con-los-elementos-modales" class="section level2">
<h2>Otra vez con los elementos modales</h2>
<p>Acordáos que hablamos hace mucho de los verbos modales y observamos que no todos los modales se pueden utilizar en todas las situaciones. Simplifiquemos esta comparación para que solo se incluyan los elementos “must” y “need to” en el BNC en los contextos orales y escritos. ¿Cuál esperamos que sea más frecuente en cada tipo de texto o situación lingüístico?</p>
<pre class="r"><code># must &lt;- dispersion(&quot;BNC&quot;, query = &quot;must&quot;, s_attribute = &quot;text_text_type&quot;)
# needto &lt;- dispersion(&quot;BNC&quot;, query = &quot;&#39;need&#39; &#39;to&#39;&quot;, s_attribute = &quot;text_text_type&quot;)</code></pre>
<p>Ahora, si vemos el componente “demographically-sampled” del BNC (sección 3.4 de Hoffman et al.), podemos formar una tabla de contingencia:</p>
<p><strong>Tabla 2:</strong> Tabla de contingencia entre <em>must</em> y <em>need to</em></p>
<table>
<thead>
<tr class="header">
<th align="left">palabra</th>
<th align="left">spoken_demographic</th>
<th align="left">written_books_periodicals</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">must</td>
<td align="left">2780</td>
<td align="left">56581</td>
</tr>
<tr class="even">
<td align="left">need to</td>
<td align="left">829</td>
<td align="left">16040</td>
</tr>
</tbody>
</table>
<p>¿Son similares las proporciones de los dos elementos modales? (Utilizemos <code>prop.table</code>.)</p>
</div>
<div id="la-prueba-del-chi-cuadrado" class="section level2">
<h2>La prueba del chi-cuadrado</h2>
<div id="la-selección-entre-un-artículo-definido-e-indefinido" class="section level3">
<h3>La selección entre un artículo definido e indefinido</h3>
<p>Como se observa en la Figura 1, las cifras del uso del artículo definido “the” y el artículo indefinido “a/n” en el inglés británico son distintas. Debemos preguntarnos, ¿por qué? Si la grámatica del inglés británico es consistente, debe de haber algunas restricciones sobre las palabras funcionales simples como “the” y “a”, ¿no? ¿Por qué no se presentan estas restrcciones de manera distinta en los diferentes registros de la lengua? Estas son las preguntas que motivan el uso del los corpus para el análisis lingüistico. Ahora, vamos a ver cómo podemos hacer una inferencia estadística, la prueba del chi-cuadrado, para concluir que hay una contengencia de verdad entre la selección entre el tipo de artículo (es decir, definido vs. indefinido) y otro factor.</p>
<div class="figure">
<img src="images/BEArticles.png" alt="" />
<p class="caption">Figura 2: Distribución de artículos y registros (Brezina, pag. 104)</p>
</div>
</div>
<div id="otro-factor" class="section level3">
<h3>Otro factor</h3>
<p>En su explicación de la prueba del chi-cuadrado, Brezina extrajo una selección de 100 observaciones de “the”, “a” o “an” del BNC y codificó manualmente varios factores. Una variable fue el “Definiteness” y otra fue el “Contextual Determination”. En la página 106 del libro, Brezina describe así:</p>
<ul>
<li><strong>contextually-determined</strong>: cases where the article marks a person, object or abstract entity previously mentioned or implied</li>
<li><strong>contextually-nondetermined</strong>: includes reference to a person, object or entity mentioned for the first time and otherwise not specified</li>
</ul>
<p>Debido a que estos criterios tienen que ver con nociones semánticas, la anotación semántica no es una opción. Se tiene que hacer manualmente, así que representa un juicio lingüístico. Utilizaremos los datos de Brezina y trataremos las datos variables como factores (repasad la discusión de los factores en la Introducción Básica a R).</p>
<pre class="r"><code>articlechoice  &lt;- read.csv(file=&quot;the_a(n).csv&quot;,header=T)
# articlechoice es ahora un data frame con columnas y filas que tienen los títulos indicados en el archivo (CSV)
articlechoice$Article_type  &lt;- as.factor(articlechoice$Article_type)
articlechoice$Context_type  &lt;- as.factor(articlechoice$Context_type)</code></pre>
<p>Si examinamos el objeto <code>articlechoice</code>, debe ser similar a la hoja de cáculo presentada en la figura 4.2 de Brezina (2018, página 105).</p>
</div>
<div id="crear-una-tabla-de-contingencia" class="section level3">
<h3>Crear una tabla de contingencia</h3>
<p>Esta función de R crear una tabla de contingencia de estos dos factores.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<pre class="r"><code>def_by_cntx  &lt;-  with(articlechoice,table(Context_type,Article_type))
def_by_cntx</code></pre>
<pre><code>##                  Article_type
## Context_type      a_indefinite b_definite
##   a_nondetermined           25          1
##   b_determined               2         72</code></pre>
<p>El resultado debe ser como se ve en la Tabla 3:</p>
<p><strong>Tabla 3:</strong> Tabla de contingencia: <em>Article_type</em> por <em>Context_type</em></p>
<table>
<thead>
<tr class="header">
<th align="left">Context_type</th>
<th align="left">a_indefinite</th>
<th align="left">b_definite</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">a_nondetermined</td>
<td align="left">25</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">b_determined</td>
<td align="left">2</td>
<td align="left">72</td>
</tr>
</tbody>
</table>
<p>Las letras “a” y “b” se han puesto como prefijos para los niveles de los factores. Esta selección es tradicional en la sociolingüística y sirve para guarantizar el orden de los niveles para el beneficio del software (como R) que asume el orden alfabético.</p>
<div id="los-números-marginales-de-las-columnas" class="section level4">
<h4>Los números marginales de las columnas</h4>
<p>Consideremos las sumas de las columnas en la tabla de contingencia:</p>
<pre class="r"><code>definiteness  &lt;- marginSums(def_by_cntx,2)
definiteness</code></pre>
<pre><code>## Article_type
## a_indefinite   b_definite 
##           27           73</code></pre>
<pre class="r"><code>definiteness[[&quot;a_indefinite&quot;]] / sum(definiteness)</code></pre>
<pre><code>## [1] 0.27</code></pre>
<p>Estos valores, 27 y 73, son exactamente los totales sombreados al pie de la Tabla 4.2 (página 109) de Brezina (2018). La probabilidad de seleccionar un artículo indefinido (en vez de un artículo definido) es 27/(27+73) = 0.27%. La probabilidad de seleccionar un artículo definido es el complemento de este resultado: 1-027=0.73. Estos cálculos son relativamente fáciles, ya que hay 100 observaciones. Sin embargo, el uso de los números margales es distintivo: revisar solo los números marginales produce una imagen del corpus mediante una de las dos variables de interés–es decir, se consideran las dos posibilidades de la otra variable. Dicho de otra forma, 27% es la probabilidad de seleccionar un artículo indefinido en vez de un artículo definido A PESAR DEL contexto.</p>
</div>
<div id="los-números-marginales-de-las-filas" class="section level4">
<h4>Los números marginales de las filas</h4>
<p>Ahora consideremos las sumas de las filas:</p>
<pre class="r"><code>cntx  &lt;-  marginSums(def_by_cntx,1)
cntx</code></pre>
<pre><code>## Context_type
## a_nondetermined    b_determined 
##              26              74</code></pre>
<pre class="r"><code>cntx[[&quot;b_determined&quot;]] / sum(cntx)</code></pre>
<pre><code>## [1] 0.74</code></pre>
<p>El valor 0.74 = 74/(26+74) es la probabilidad de que el contexto es “determined”, a pesar de que la palabra sea <em>the</em> o <em>a(n)</em>. Si ignoramos “definiteness”, sabemos la probabilidad de los dos valores posibles de <code>Context_type</code>, 0.74 (“determined”) y 0.26 (“nondetermined”).</p>
</div>
<div id="las-hipótesis" class="section level4">
<h4>Las hipótesis</h4>
<p>Ahora formulemos dos hipótesis:</p>
<ul>
<li><strong>H<sub>0</sub>:</strong> El tipo de artículo y el tipo de contexto son independientes.</li>
<li><strong>H<sub>1</sub>:</strong> El tipo de artículo y el tipo de contexto no son independientes.</li>
</ul>
<p>La primera de estas hipótesis es la hipótesis nula. El término “nulo” en este contexto significa algo como hipóteis “por defecto”. Por primera vista, no parece que haya una razón para asumir que dos valores lingüísticos distintos que se han caracterizado de maneras distintas sean relacionados. Si observamos evidencia al contrario, abandonamos la hipótesis nula y aceptamos la hipótesis alternativa.</p>
<p>La diferencia entre dos hipótesis tiene que ver con la palabra “independiente”. Esta palabra se entiende en el sentido de <a href="https://mathworld.wolfram.com/IndependentEvents.html">la independencia probabilística</a>. Si son independientes nos variables, su distribución disjunta es el producto de sus probabilidades. Si es verdad la H0, la muestra Tabla debe ser como la siguiente:</p>
<p><strong>Tabla 4:</strong> Las frecuencia que se esperan si las variables de fila y de columna son independientes</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Context_type</th>
<th align="left">a_indefinite</th>
<th align="left">b_definite</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">a_nondetermined</td>
<td align="left">P(indefinite)× P(nondetermined)× samplesize</td>
<td align="left">P(definite)× P(nondetermined)× samplesize</td>
</tr>
<tr class="even">
<td align="left">b_determined</td>
<td align="left">(indefinite)× P(determined)× samplesize</td>
<td align="left">P(definite)× P(determined)× samplesize</td>
</tr>
</tbody>
</table>
<p>Baja la suposición que es verdad la H0, cada celda de la tabla de contingencia debe tener un número tde observacioens que es el producto de las probabilidades que estimamos arriba. <code>samplesize</code> es el total–es decir, 100 observaciones. Multiplicar todas estas probabilidades produce los valores numéricos que se presentan en la siguiente tabla. Comparemos estos resultados con la Tabla 4.5 de Brezina (página 114).</p>
<p><strong>Tabla 5:</strong> Las sumas esperadas</p>
<table>
<thead>
<tr class="header">
<th align="left">Context_type</th>
<th align="left">a_indefinite</th>
<th align="left">b_definite</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">a_nondetermined</td>
<td align="left">7.02</td>
<td align="left">18.98</td>
</tr>
<tr class="even">
<td align="left">b_determined</td>
<td align="left">19.98</td>
<td align="left">54.02</td>
</tr>
</tbody>
</table>
<p>La Tabla 5 es lo que esperamos baja la suposición de la hipótesis nula. Pero, lo que resulta son las observaciones que se presentaron en la Tabla 3. El estatus distinto de los valores esperados <strong>E</strong> versus los valores observados <strong>O</strong> presentado en una tabla de contingencia 2x2 se resume en la descripción de Baroni y Evert (ver las diapositivas).</p>
</div>
<div id="la-descrepancia-entre-las-sumas-esperadas-y-las-observadas" class="section level4">
<h4>La descrepancia entre las sumas esperadas y las observadas</h4>
<p>Decimos que hay un desequilibio con una tabla de contingencia cuando existe una descripancia grande entre los valores esperados y los observados (indicados en la Tabla 3). Sin embargos, debemos preguntarnos, ¿cómo sabemos si esta descrepancia es demasiado grande? La cantidad expresada por <span class="math inline">\(\frac{(O-E)^2}{E}\)</span> evalúa esta descrepancia. Sumamos esta estadística de prueba, a través de todas las celdas, y producimos un cálculo que tiene una distribución <span class="math inline">\(\chi^2\)</span>. La distribución <span class="math inline">\(\chi^2\)</span> representa una distribución de las sumas de las cuadradas de las variables normales estándares <em>k</em>. Estas distribuciones se presentan en la siguiente gráfica con números que representan los grados de libertad (‘degrees of freedom’.)</p>
<p><img src="SPAN8450_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>En este escenario de probar nuestras hipótesis, nosotros calculamos una probabilidad para la variable <code>Article type</code> y también para <code>Context type</code>. Entonces, en vez de tener <span class="math inline">\(2 \times 2 = 4\)</span> grados de libertad, solo tenemos <span class="math inline">\((2-1)\times(2-1)=1\)</span> grados de libertad.</p>
</div>
<div id="probar-las-hipótesis" class="section level4">
<h4>Probar las hipótesis</h4>
<p>Las curvas en la figura previa nos muestran la probabilidad de ciertos valores de la estadística chi-cuadrado. Ahora, podemos pregunta: ¿qué es la probabilidad de una estadística chi-cuadrado <strong>particular</strong> que hemos calculado de una tabla de contingencia que ya formamos (basada en datas de un corpus)? Este proceso es lo que hace la prueba chi-cuadrado. Calcula esta estadística de prueba y determina la probabilidad de observar una tabla de contingencia que el mismo o un valor más extremo de la estadística de prueba. En R, esta función se llama <code>chisq.test</code>.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<pre class="r"><code>chisq.test(def_by_cntx,correct=F)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  def_by_cntx
## X-squared = 85.249, df = 1, p-value &lt; 2.2e-16</code></pre>
<p>Observemos la última línea de los resultados de la función <code>chisq.test</code>. X-squared = 85.249 representa la suma de las descrepancias, descrita en las secciones anteriores y por Brezina (página 113). Se puede calcular manualmente con la información que nos produce R:</p>
<pre class="r"><code>result  &lt;- chisq.test(def_by_cntx)
E  &lt;- result$expected
O &lt;- result$observed
sum((O - E)^2 / E)</code></pre>
<pre><code>## [1] 85.24868</code></pre>
<p>El ‘p-value’ es la probabilidad de tomar una muestra de este valor de <code>X-squared value</code> o un valor mayor de la distribución <span class="math inline">\(\chi^2\)</span> con la pregunta: ¿cuánta es el área que se encuentra bajo la curva de la distribución del chi-cuadrado que va más allá del número 85.249?</p>
<pre class="r"><code>pchisq(85.249,df=1,lower.tail=F)</code></pre>
<pre><code>## [1] 2.630615e-20</code></pre>
<p>La respuesta es que casi ninguna (área bajo la curva). Existe una probabilidad casi inexistente de que se observaría aleatoriamente una estadística de prueba tan extrema si fuera verdad la hipótesis nula. El resultado de esta prueba es que la evidencia sacada del BNC es suficiente para rechazar la hipótesis nula. En nuestro escenario, nos queda la hipótesis alternativa, es decir, que la selección del tipo de artículo es un hecho afectado por el tipo de contexto. Como vimos en la Tabla 3, los autores suelen utilizar un artículo definido cuando mencionan algo por primera vez.</p>
</div>
</div>
</div>
</div>
<div id="a-semana-7" class="section level1">
<h1>9a Semana</h1>
<p><strong>Los colocados</strong> (‘collocates’) son las palabras suelen aparecer juntas. Brezina (sección 3.2) utiliza el término “nodo” (‘node’) para la palabra que nos interesa y introduce la metáfora de un campo magnético para describir la vecindad donde se encuentran las colocaciones. Según <a href="https://uga.view.usg.edu/d2l/le/content/2055335/viewContent/32427992/View">Evert</a>, esta configuración es lo que se llama un “surface co-occurrence”. Podemos utilizar la estadística de chi-cuadrado para producir un rango de estas co-ocurrencias dentro de la ‘ventana’ indicada. Las palabras que ocurren con más frecuencia que se espera deben aparcer en la parte encima de este rango.</p>
<div id="un-ejemplo-love-affair" class="section level2">
<h2>Un ejemplo: <em>love affair</em></h2>
<p>Consideremos la palabra “love” como una palabra de interés. ¿Con qué ocurre? Podemos utilizar la función <code>coocurrenences</code> en <code>polmineR</code> para contestar esta pregunta. Notaos que tenemos que seguir los pasos normales para utilizar esta técnica.</p>
<pre class="r"><code>#love_co &lt;- cooccurrences(&quot;BNC&quot;, query = &quot;love&quot;, left = 0, right=5, method=&quot;chisquare&quot;, verbose=T)
#love_df  &lt;- as.data.frame(love_co)</code></pre>
<p>Si hacemos este primer mandato, se produce una mensaje que nos informa que se encontraron 20160 casos de la palabra “love” en el BNC.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> El segundo mandato (<code>as.data.frame</code>) produce un data frame de la lista de co-ocurrencias.</p>
<pre><code>head(love_df)</code></pre>
<p>Este data frame muestra que un colocado prominente de la palabra “love” es “affair”. Las filas están en orden por su estadística de la prueba del chi-cuadrado, y el colocado “affair” aparece en la primera fila. Si consideramos algunos de las otras columnas, observamos que la selección de casos donde “love” occur con “affair” son 3079 casos. De todos estos casos, 182 de ellos se observaron dentro de la ventana de las cinco palabras que siguen la palabra “love”. 2897 de estos casos no se observaron en esta ventana. Podemos utilizar estos números para crear una tabla de contingencia.</p>
<div id="la-tabla-de-contingencia" class="section level3">
<h3>La tabla de contingencia</h3>
<p>Los números en el data frame <code>love_df</code> son suficientes para completar las celdas grises de la tabla 3.1 de Brezina (página 70). Se presentan en la siguiente tabla.</p>
<p><strong>Tabla 1</strong>: Tabla de contigencia para una ventana de colocaciones de cinco palabras a la derecha del nodo</p>
<table>
<thead>
<tr class="header">
<th align="left">colocado</th>
<th align="left">colocado presente (‘affair’)</th>
<th align="left">colocado ausente</th>
<th align="left">Totales</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cerca de “love”</td>
<td align="left">182</td>
<td align="left">100618</td>
<td align="left">20160 casos × 5 ventana = <code>love_co@size_coi</code></td>
</tr>
<tr class="even">
<td align="left">no cerca de “love”</td>
<td align="left">2897</td>
<td align="left">112032504</td>
<td align="left"><code>love_co@size_ref =112035401</code></td>
</tr>
<tr class="odd">
<td align="left">Totales</td>
<td align="left">3079</td>
<td align="left">12133122</td>
<td align="left"><code>size("BNC")</code> - 20160 = 112136201</td>
</tr>
</tbody>
</table>
<p>Sin consideramos la ventana de cinco palabras a la derecha, tenemos aproximadamente 20150*5=100800 oportunidades para la co-ocurrencia.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> Podemos pensar de cada caso o (a) como parte del conjunto de casos con constan del <code>love_co@size_coi</code> o (b) como parte del corpus de referencia, es decir, los casos en el BNC que no se ubican cerca de cualquier instancia de la palabra “love”. La cantidad de estos casos equivale a <code>love_co@size_ref</code>.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
</div>
<div id="la-frecuencia-experada-del-colocado" class="section level3">
<h3>La frecuencia experada del colocado</h3>
<p>Ya podemos calcular lo que llama Brezina el <strong>random co-ocurrence baseline</strong>. Esto se refiere al número esperado de veces que se debería observar “affair” como co-ocurrencia dentro de la ventana de cinco palabras de “love” si las frecuencias fueran el producto sus probabilidades de atestación individual.</p>
<pre class="r"><code>#r1  &lt;-  love_df[love_df$word==&quot;love&quot;,]$count_partition
#c1  &lt;-  love_df[love_df$word==&quot;affair&quot;,]$count_partition
#n &lt;- size(&quot;BNC&quot;) - 20160
# (r1*c1*5)/n
#[1] 2.767734</code></pre>
<p>El denominador es el total completo: el tamaño de corpus menos la cantidad de los casos del nodo. Por definición, estos no so candidatos para la co-ocurrencia (leer “The most sensible definition…”, Evert, página 27). El numerador es el producto de la frecuencia del nodo, la frecuencia del colocado, y el tamaño de la ventana presentados mediante la expresión 3.2 en la página 69 de Brezina. El valor numérico de esta fracción es como se presenta en la primera columna del data frame <code>love_df</code>–es decir, en la columna <code>exp_coi</code>. Esta columna es la frecuencia esperada de la palabra “affair” como un colocado a la derecha de “love”. Por supuesto, este número es solamente el valor de la celda E_11 de la matriz de frecuencias esperadas.</p>
<p><strong>expected frequency of collocation (corrected)</strong> = <span class="math inline">\(\frac{(node frequency)\times(collocate frequency)\times(window size)}{no. of tokens in text or corpus}\)</span></p>
</div>
<div id="las-frecuencias-observadas-y-esperadas" class="section level3">
<h3>Las frecuencias observadas y esperadas</h3>
<p>Acordáos que la prueba del chi cuadrado utiliza la descrepancia entre la matriz de frecuencias esperadas y la matriz de frecuencias observadas. Completamos la segunda matriz a base de los resultados sacados de <code>cooccurences</code> con tal de que distinguamos cuidadosamente entre los casos que se ubican cerca de “love” y los demás.</p>
<pre class="r"><code>#affair  &lt;- love_df[love_df$word==&quot;affair&quot;,]$count_partition

#o11  &lt;-  love_df[love_df$word==&quot;affair&quot;,]$count_coi  # count of co-occurrences within window
#o21  &lt;-  affair - o11
#o12  &lt;-  love_co@size_coi - o11
#o22  &lt;-  n - (o11+o21+o12) # grand total minus all the others

#O &lt;- matrix(c(o11,o21,o12,o22),ncol=2)
#colnames(O)  &lt;-  c(&quot;affair present&quot;, &quot;affair not present&quot;)
#rownames(O) &lt;- c(&quot;near love&quot;, &quot;not near love&quot;)</code></pre>
<p>Calculamos los números marginales para llegar a las filas y las columnas que vimos en la Tabla 1.</p>
<pre class="r"><code>#r1 &lt;- marginSums(O,1)[[1]]
#r2 &lt;- marginSums(O,1)[[2]]
#c1 &lt;- marginSums(O,2)[[1]]
#c2 &lt;- marginSums(O,2)[[2]]</code></pre>
<p>Con estos números, podemos calculamos los números de las atestaciones esperados según la hipótesis nula.</p>
<pre class="r"><code>#f &lt;- function (numerator1,numerator2,denominator) { exp(log(numerator1)+log(numerator2)-log(denominator)) } # in log space to avoid overflow
#E &lt;- matrix(c(f(r1,c1,n),f(r2,c1,n),f(r1,c2,n),f(r2,c2,n)),ncol=2)
#colnames(E)  &lt;-  c(&quot;affair present&quot;, &quot;affair not present&quot;)
#rownames(E) &lt;- c(&quot;near love&quot;, &quot;not near love&quot;)</code></pre>
<p>Dado el tamaño tan grande del corpus, tenemos que realizar los cálculos con los logaritmos, donde la multiplicación se convierte en la suma.</p>
<pre class="r"><code>#&gt; E
#              affair present affair not present
#near love           2.767734           100797.2
#not near love    3076.232266        112032324.8
#&gt; sum((O - E)^2 / E)
#[1] 11617.44</code></pre>
<p>Recuperamos el valor del <code>chisquare</code> que ya calculamos con la función <code>cooccurences</code> que se encontró en la primea fila del data frame <code>love_df</code>. Esta demostración nos destaca el hecho de que el rango de los colocados a la derecha de “love” es la misma estadística del chi-cuadrado que ya hemos utilizado para probar las hipótesis. ¿Habrá otras maneras de producir un rango de los colocados?</p>
</div>
</div>
<div id="las-medidas-de-asociación" class="section level2">
<h2>Las medidas de asociación</h2>
<p>Ya hemos visto el uso de las pruebas del chi-cuadrado para los colocados de la palabra “love”.</p>
<pre class="r"><code># last time
#love_chisq  &lt;-  cooccurrences(&quot;BNC&quot;, query = &quot;love&quot;, left = 0, right=5, method=&quot;chisquare&quot;)
#&gt; as.data.table(love_chisq)[word==&quot;affair&quot;]
#     word word_id count_partition count_coi count_ref  exp_coi chisquare rank_chisquare
#1: affair    7668            3079       182      2897 2.767734  11617.44              1
# this time
#love_ll  &lt;-  cooccurrences(&quot;BNC&quot;, query = &quot;love&quot;, left = 0, right=5, method=&quot;ll&quot;)
#&gt; head(love_ll,10)
#      word word_id count_partition count_coi count_ref     exp_coi     exp_ref       ll rank_ll
 #1:    you      66          574132      2188    571944  516.091192  573615.909 3010.071       1
 #2:     &#39;&#39;     165          752264      2347    749917  676.215268  751587.785 2531.337       2
 #3:   love     876           20160       417     19743   18.121962   20141.878 1827.170       3
 #4:   with      43          639450      1835    637615  574.805990  638875.194 1758.041       4
 #5:    him     920          152878       818    152060  137.423082  152740.577 1564.793       5
 #6:      .      22         4715138      6772   4708366 4238.469880 4710899.530 1348.064       6
 #7:    her      53          287910      1019    286891  258.804273  287651.196 1280.476       7
 #8:     me     395          129238       679    128559  116.172924  129121.827 1277.563       8
 #9: affair    7668            3079       182      2897    2.767734    3076.232 1176.202       9
#10:    God    2104           20382       279     20103   18.321520   20363.678 1002.179      10</code></pre>
<p>En este caso, la palabra “affair” no resulta ser el colocado con el rango más alto. Los resultados de esta segunda métrica la tiene en la novena posición.</p>
<p>El método por defecto <code>method=ll</code> produce una tabla de contingencia con probabilidades de ‘log-likelihood’.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> Esta métrica representa una medida de asociación diferente que pone los pronombres “you”, “him”, y “her” en posiciones más altas en en rango que la de “affair”. Sin examinamos la columna de <code>count_partition</code>, observamos que estas palabas tienen frecuencias de observación mucho más altas que la palabra “affair”. Evidentemente, la métrica log-likelihood prioriza *la frecuencia<strong> sobre </strong>la exclusividad**. Hay más o menos cuarenta medidas de asociación descritas por <a href="http://www.collocations.de/AM/">Evert</a> y que se han implementado en <a href="http://www.collocations.de/software.html">el UCS/R System</a>. Este programa se puede utilizar con nuestro servidor.</p>
<div id="describrir-patrones" class="section level3">
<h3>Describrir patrones</h3>
<p>Consideremos las palabras “bachelor” y “spinster” en el BNC. Esta palabras se refieren a los hombres y las mujeres solteros, respectivamente. ¿Podemos utilizar el corpus para entender los estereotipos asociados con estas palabras? Vamos a ver los colocados:</p>
<pre class="r"><code>#&gt; b &lt;- cooccurrences(&quot;BNC&quot;,&quot;bachelor&quot;)
#&gt; head(b,10)</code></pre>
<p>Parece que la palabra “eligible” es un colocado exclusivo de “bachelor”. Sin embargo, las palabras “a”, “was” y “his” no parecen ser relevantes. Es común excluir palabras como esas (los “stopwords”) de la concordancia, por ejemplo mediante el uso de la función <code>subset</code> de PolmineR.</p>
<pre class="r"><code>#uninteresting  &lt;- c(&quot;bachelor&quot;,&quot;spinster&quot;,&quot;``&quot;,&quot;&#39;&#39;&quot;,punctuation,tm::stopwords(&quot;en&quot;))
#bach &lt;- cooccurrences(&quot;BNC&quot;, query = &quot;bachelor&quot;, right = 5, left = 5) %&gt;% subset(!tolower(word) %in% uninteresting)
#spin &lt;- cooccurrences(&quot;BNC&quot;, query = &quot;spinster&quot;, right = 5, left = 5) %&gt;% subset(!tolower(word) %in% uninteresting)</code></pre>
<p>Con estas concordancias, se nota el uso del operador de R <code>%in% que se utiliza para comparar una palabra con una lista pre-determinada de palabras (es decir, el "stoplist") que no importan. El signo de interrogación</code>!` es el operador negación de R que permite definir una condición que especifica las palabras que <strong>no</strong> son relevantes.</p>
<p>Podemos utilizar el paquete <code>ggplot2</code> para examinar los resultados con un “Cleveland dotchart”. El objecto que produce la función <code>cooccurrences</code> incluye una opción que llama <code>stat</code>, lo cual representa <a href="https://rdatatable.gitlab.io/data.table/">un tipo de data frame especial</a>. La expresión <code>1:14</code> crea <a href="https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Generating-regular-sequences">un vector de números</a> con un orden ascendente; este vector de índice (<a href="https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Index-vectors">caso 2 en los R docs</a>) dentro de los corchetes limita la gráfica a los 14 colocados más prominentes.</p>
<pre class="r"><code>#&gt; library(ggplot2)
#&gt;ggplot(bach@stat[1:14],aes(x=ll,y=reorder(word,-rank_ll))) + geom_point(color=&quot;blue&quot;) +
#    labs(title=&quot;\&quot;bachelor\&quot; in BNC&quot;,x=&quot;log-likelihood&quot;,y=&quot;collocate&quot;)
#&gt;ggplot(spin@stat[1:14],aes(x=ll,y=reorder(word,-rank_ll))) + geom_point(color=&quot;red&quot;) +
#    labs(title=&quot;\&quot;spinster\&quot; in BNC&quot;,x=&quot;log-likelihood&quot;,y=&quot;collocate&quot;)</code></pre>
<p><img src="images/BachelorPlot.png" /> <img src="images/SpinsterPlot.png" /> Se observa que, con la palabra “spinster”, la palabra “elderly” (y también “dried-up”, “cold-hearted”, “sex-starved” y “rape”) tiene un rango alto, lo cual parece apoyar la idea de que es un término despectivo en en inglés británico. En el capítulo 5 de Baker (2006, <em>Using corpora in discourse analysis</em>), se encuentra mucha más información sobre este tema.</p>
</div>
</div>
<div id="la-frecuencia-de-ocurrencia" class="section level2">
<h2>La frecuencia de ocurrencia</h2>
<p>La medida de asociación más simple es la frecuencia cruda de los colocados posibles. Esta medida se indica como “ID #1” en la tabla 3.3 de Brezina (página 72). Ya hemos visto que la palabra “love” coloca con la palabra “affair” con una frecuencia de 182 en el BNC. ¿Existen pares de palabras que tienen frecuencias más altas de atestación? Este cálculo se realiza mediante la función <code>ngrams</code> de PolmineR.</p>
<pre><code>#&gt; bigrams  &lt;- ngrams(&quot;BNC&quot;,n=2)
#&gt; greater1k  &lt;-  subset(bigrams, count &gt; 1000 &amp; !(word_1 %in% uninteresting | word_2 %in% uninteresting))
#&gt; head(sort(greater1k,by=&quot;count&quot;,decreasing=T),10)
  word_1 word_2 count
 1:      I     &#39;m 62209
 2:     It     &#39;s 45283
 3:      I  think 41199
 4:    per   cent 38033
 5:      I    &#39;ve 36332
 6:     ca    n&#39;t 28381
 7:      I    &#39;ll 26968
 8:    &#39;ve    got 26449
 9:   That     &#39;s 24667
10:      I   mean 24214</code></pre>
<p>Y, naturalmente, podemos extender este proceso a los grupos de tres.</p>
<pre class="r"><code>#&gt;mypunctuation  &lt;-  c(punctuation,&quot;``&quot;,&quot;&#39;&#39;&quot;)
#&gt;trigrams  &lt;-  ngrams(&quot;BNC&quot;,n=3)
#&gt;nopunct_greater10k  &lt;-  subset(trigrams, count &gt; 10000 &amp; !(word_1 %in% mypunctuation | word_2 %in% mypunctuation | word_3 %in% mypunctuation))

#&gt;bnc_all  &lt;- sort(nopunct_greater10k,by=&quot;count&quot;,decreasing=T)</code></pre>
<p>La siguiente tabla muestra que el “trigram” más atestado en el BNC es “I don’t”, seguido por “one of the”.</p>
<table>
<thead>
<tr class="header">
<th align="left">palabra_1</th>
<th align="left">palabra_2</th>
<th align="left">palabra_3</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. I</td>
<td align="left">do</td>
<td align="left">n’t</td>
<td align="left">37090</td>
</tr>
<tr class="even">
<td align="left">2. one</td>
<td align="left">of</td>
<td align="left">the</td>
<td align="left">29737</td>
</tr>
<tr class="odd">
<td align="left">3. the</td>
<td align="left">end</td>
<td align="left">of</td>
<td align="left">20699</td>
</tr>
<tr class="even">
<td align="left">4. as</td>
<td align="left">well</td>
<td align="left">as</td>
<td align="left">16848</td>
</tr>
<tr class="odd">
<td align="left">5. part</td>
<td align="left">of</td>
<td align="left">the</td>
<td align="left">16666</td>
</tr>
</tbody>
</table>
<p>Esta extensión hacia grupos más grandes también se puede hacer con otras medidadas de asociación mediante la expansión de la tabla de contingencia. Un ejemplo de este tipo de implementación es <a href="https://metacpan.org/pod/release/TPEDERSE/Text-NSP-1.31/lib/Text/NSP/Measures/3D/MI.pm">el ngram statistics package de Ted Pedersen</a>, lo cual produce medidas de 2, 3, o 4 dimensions.</p>
</div>
<div id="colocados-de-la-derecha-de-un-nodo-complejo" class="section level2">
<h2>Colocados de la derecha de un nodo complejo</h2>
<p>Podemos replicar el trabajo de Scott y Tribble (2006) con una consideración del grupo “one of the” como un nodo. ¿Cómo varían sus colocados de la derecha como función del género (‘genre’)?</p>
<pre class="r"><code>#&gt;academic  &lt;-  partition(&quot;BNC&quot;, text_derived_type = &quot;academic&quot;)
#&gt;spoken  &lt;-  partition(&quot;BNC&quot;, text_derived_type = &quot;spoken_conversation&quot;)

#&gt;oneofthe_acad &lt;- cooccurrences(academic,  query = &quot;&#39;one&#39; &#39;of&#39; &#39;the&#39;&quot;, cqp = T, right = 1, left = 0) %&gt;% subset(!tolower(word) %in% uninteresting)
#&gt;oneofthe_spok &lt;- cooccurrences(spoken,  query = &quot;&#39;one&#39; &#39;of&#39; &#39;the&#39;&quot;, cqp = T, right = 1, left = 0) %&gt;% subset(!tolower(word) %in% uninteresting)</code></pre>
<p>Ya que hemos producido una lista de los colocados a la derecha incluídos en <code>Academic Text</code> y <code>Spoken Conversation</code>, podemos determinar cuales son los más atestados. Si tratamos los vectores como conjuntos, podemos descalificar las palabras como “first” que coloca frecuencamente con esta expresión (“one of the”) en textos de los dos géneros.</p>
<pre class="r"><code># solo consideramos los primeros 10 colocados
#&gt;common  &lt;-  intersect(oneofthe_acad@stat[1:10,word],oneofthe_spok@stat[1:10,word])
#&gt;distinctive  &lt;-  setdiff(oneofthe_acad@stat[1:10,word],common)</code></pre>
<p>Este proceso nos da:</p>
<pre class="r"><code>#&gt;head(oneofthe_spok@stat)
#&gt;head(oneofthe_acad@stat[word %in% distinctive,])</code></pre>
<p>Estos resultados confirman el argumento de Scott y Tribble que la expresión “one of the main” y “one of the major” son expresiones distinctamente académicas.</p>
<!--
**Tarea:**
-->
<hr />
</div>
</div>
<div id="recursos" class="section level1 tabset tabset-fade tabset-pills">
<h1>Recursos</h1>
<div id="tools" class="section level2 unnumbered">
<h2>Tools</h2>
<ul>
<li><a href="http://research.franklin.uga.edu/linglab/corpora">Collection of corpus resources available to UGA faculty and students</a></li>
<li><a href="http://cwb.sourceforge.net/">The IMS Open Corpus Workbench</a>: The IMS Open Corpus Workbench (CWB) is a collection of open-source tools for managing and querying large text corpora (ranging from 10 million to 2 billion words) with linguistic annotations. Its central component is the flexible and efficient query processor CQP.</li>
<li><a href="http://corpora.lancs.ac.uk/lancsbox/">LANCSBox</a>: software package for the analysis of language data and corpora</li>
<li><a href="http://corpora.lancs.ac.uk/stats/index.php">Lancaster Stats Tools online</a>: The website provides practical support for the analysis of corpus data using a range of statistical techniques.</li>
<li><a href="https://www.ldc.upenn.edu/">Linguistic Data Consortium</a>: A great resource for language corpora; and UGA has an institutional subscription!!</li>
<li><a href="https://corpus-analysis.com/">Tools for Corpus Linguistics</a>: A long list of corpus-related resources that’s always being updated</li>
</ul>
</div>
<div id="generales" class="section level2 unnumbered">
<h2>Generales</h2>
<ul>
<li><a href="http://www.corpusdelespanol.org/">Corpus del Español</a>: Spanish corpus compiled by BYU</li>
<li><a href="https://www.rae.es/recursos/banco-de-datos/crea">El Corpus de Referencia del Español Actual (CREA)</a></li>
<li><a href="https://www.rae.es/recursos/enlaces-externos/atlas-sintactico-del-espanol">El Atlas Sintáctico del Español (ASinEs)</a></li>
<li><a href="http://catalog.elra.info/en-us/repository/search/?q=Spanish">European Language Resources Association (ELRA)</a></li>
<li><a href="http://eslora.usc.es/">ESLORA 2.0: Corpus para el estudio del español oral</a></li>
</ul>
</div>
<div id="históricos" class="section level2 unnumbered">
<h2>Históricos</h2>
<ul>
<li><a href="https://www.rae.es/recursos/banco-de-datos/corde">El Corpus Diacrónico del Español (CORDE)</a></li>
<li><a href="http://web.frl.es/CNDHE/view/inicioExterno.view;jsessionid=2E34C1C1AF321C2A31535DD5369E994F">Corpus del Nuevo Diccionario Histórico del Español</a></li>
<li><a href="http://www.cordiam.org/">Corpus Diacrónico y Diatópico del Español de América</a>: El Corpus Diacrónico y Diatópico del Español de América reúne tres conjuntos documentales; Cordiam-Documentos, Cordiam-Literatura y Cordiam-Prensa.</li>
<li><a href="http://www.corpuscharta.es/">Corpus Hispánico y Americano en la Red: Textos Antiguos</a>: CHARTA se concibe como un proyecto global para la edición y análisis lingüístico de textos archivísticos en español de los siglos XII al XIX.</li>
<li><a href="http://corpuscodea.es/">El corpus CODEA (Corpus de Documentos Españoles Anteriores a 1800)</a></li>
<li><a href="http://ps.clul.ul.pt/">Project P.S. Post Scriptum</a></li>
<li><a href="http://www.bibliamedieval.es/index.php">Biblia Medieval</a></li>
</ul>
</div>
<div id="sociolingüístico" class="section level2 unnumbered">
<h2>Sociolingüístico</h2>
<ul>
<li><a href="https://cesa.arizona.edu/">Corpus del Español en el Sur de Arizona (CESA)</a></li>
<li><a href="https://www.rae.es/recursos/banco-de-datos/corpes-xxi">El Corpus del Español del Siglo XXI (CORPES XXI)</a></li>
<li><a href="http://preseea.linguas.net/">PRESEEA</a>: A collection of sociolinguistic data from around the Spanish-speaking world.</li>
<li><a href="http://bangortalk.org.uk/speakers.php?c=miami">CANOLFAN: The Miami corpus consists of conversations by Spanish-English bilinguals</a></li>
<li><a href="http://bangortalk.org.uk/speakers.php?c=miami&amp;fbclid=IwAR1gYuXaXUhYw-u7_B0zS2kMwdMYyd-pQW_JGTkjrGxdoL11AgpcRsZFYI8">Corpus MIAMI</a></li>
<li><a href="https://itcdland.csumb.edu/~eabrown/">Corpus of Mexican Spanish in Salinas</a></li>
<li><a href="http://corpusrural.es/">COSER: Corpus oral y Sonora del Español Rural</a></li>
<li><a href="http://spanishintexas.org/">Spanish in Texas</a></li>
<li><a href="https://byts.commons.gc.cuny.edu/">Bilingual Youth Texts</a></li>
<li><a href="https://www.webcorpora.org/">COW</a>: High Quality Web Corpora</li>
</ul>
</div>
<div id="adquisición" class="section level2 unnumbered">
<h2>Adquisición</h2>
<ul>
<li><a href="http://cedel2.learnercorpora.com/">CEDEL2: Corpus Escrito del Español L2 (versión 2)</a></li>
<li><a href="http://www.splloc.soton.ac.uk/">Spanish Learner Language Oral Corpora (splloc)</a></li>
<li><a href="https://hispanismo.cervantes.es/congresos-y-cursos/corpus-aprendices-espanol-caes-concepcion-explotacion-caes">El Corpus de aprendices del español (CAES)</a></li>
</ul>
</div>
<div id="otras-lenguas-románicas" class="section level2 unnumbered">
<h2>Otras lenguas románicas</h2>
<ul>
<li><a href="http://www.corpusdoportugues.org/">Corpus do Português</a>: Portuguese corpus compiled by BYU</li>
</ul>
<!--
- <a href="https://uclouvain.be/en/research-institutes/ilc/cecl/corpora.html">Center for English Corpus Linguistics (Louvain)</a>: A collection of several useful corpus resources
- <a href="http://lingtools.uoregon.edu/coraal/explorer/">CoRAAL</a>: Corpus of Regional African American Language, developed and hosted by the University Oregon
- <a href="https://cqpweb.lancs.ac.uk/">Lancaster Corpus Resources</a>
- <a href="https://cesa.arizona.edu/links-other-sociolinguistic-corpora">University of Arizona Corpus Resources</a>
- [SPeech Across Dialects of English (SPADE)](https://spade.glasgow.ac.uk/): This is a very cool project that seeks to develop tools for doing large-scale analysis of speech data.

-->
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Gracias a Donald Dunagan por la preparación de este documento.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Verifica que la versión del CQP que utilizas es la versión apropiada con el mandato <code>cqp -version</code>. Debe ser la versión 3.4.22.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Estos apuntes se han basado en los apuntos de curso del profesor John Hale.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Los <em>Hapax Legomena</em> son palabras que solo aparecen una vez. En la sección 2.3 de Brezina, este término griego se introduce.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>También os encontré un script que automatiza el proceso descrito en el Windows Setup Guide. Hay que (i) descargar el archivo <code>kucera_ polminer_ prep-DOT-BAT-RENAME-ME</code> para tu máquina local, (ii) cambiar el nombre a <code>kucera_polminer_prep.bat</code> y (iii) hacer un double-click. Notáos que este proceso solo se aplica con los usuarios de Windows.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Con el macOS, el paquete se puede instalar con el R básico. Sin embargo, con Windows, el proceso de instalar el paqueste del código básico requiere el uso de Rtools. Por eso, el profesor Blätte proporciona una versión binaria–es decir, una versión que se ha compilado. El argumento adicional <code>type="win.binary"</code> requiere esta versión. Eventualmente, los dos paquetes se distribuirán por el archivo CRAN. Por ahora, la versión más reciente está disponible en el depósito personal del profesor Blätte. Se debe consultar la discusión de paquetes al principio de la introducción al <code>tidyverse</code> preparado por Jonathan Jones.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Este ejemplo se adopto de la sección 4.4 de Jockers 2020.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Sin esta expresión, sería necesario hacer referencia a <code>articlechoice$Context_type</code> en vez de solo <code>Context_type</code>.<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>El argumento adicional <code>correct=F</code> apaga lo que se llama el “Yate’s correction” en este ejemplo. Para más información, consulta la nota 8 en la página 113 de Brezina (2018).<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Se puede explorar un objeto de ‘cooccurences’ mediante el htmlwidget como <code>as(love_co,"htmlwidget")</code><a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>Esta estimación es aproximado porque la atestación final puede estar tan cerca al principio o al final del corpus que la ventana de colocación se corta. De manera similar, el investigador puede imponer unas restricciones que determinen que la ventana no pueda extender más allás de las fronteras de una oración. Estas restricciones requieren que las fronteras oracionales sean anotadas en el corpus–por ejepmlo, con los atributos estructurales como <s> y </s>.<a href="#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>El signo <code>@</code> extrae un valor de un luegar de un objeto definido dentro del <a href="http://adv-r.had.co.nz/OO-essentials.html#s4">S4 object system</a>. Es paralelo a la notación de <code>4</code> que describió Jonathan Jones en su introducción a R. it’s analogous to the dollar notation that you learned about in Jonathan Jones’ introduction to base R.<a href="#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Un trabajo yaclásico que defende la idea de utilizar los log-likelihood es el trabajo de <a href="https://www.aclweb.org/anthology/J93-1003/">Dunning (1993)</a>.<a href="#fnref13" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

<footer role="contentinfo" id="site-footer">

<!-- /.bottom-menu -->
	<p class="copyright">&#169; 2020,
		powered by <a href="http://www.r-project.org">R</a> + <a href="http://rmarkdown.rstudio.com">RMarkdown</a> + <a href="http://github.com">Github</a>.</p>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
