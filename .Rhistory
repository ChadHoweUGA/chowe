#########
## 1. Run this first
Sys.setenv("CORPUS_REGISTRY" = "/Volumes/cwb_registry/mac_registry")
library(polmineR)
corpus()
b <- cooccurrences("BNC","bachelor")
head(b,10)
uninteresting  <- c("bachelor","spinster","``","''",punctuation,tm::stopwords("en"))
bach <- cooccurrences("BNC", query = "bachelor", right = 5, left = 5) %>% subset(!tolower(word) %in% uninteresting)
spin <- cooccurrences("BNC", query = "spinster", right = 5, left = 5) %>% subset(!tolower(word) %in% uninteresting)
library(ggplot2)
ggplot(bach@stat[1:14],aes(x=ll,y=reorder(word,-rank_ll))) + geom_point(color="blue") +
labs(title="\"bachelor\" in BNC",x="log-likelihood",y="collocate")
ggplot(spin@stat[1:14],aes(x=ll,y=reorder(word,-rank_ll))) + geom_point(color="red") +
labs(title="\"spinster\" in BNC",x="log-likelihood",y="collocate")
ggplot(bach@stat[1:14],aes(x=ll,y=reorder(word,-rank_ll))) + geom_point(color="blue") +
labs(title="\"bachelor\" in BNC",x="log-likelihood",y="collocate")
bigrams  <- ngrams("BNC",n=2)
greater1k  <-  subset(bigrams, count > 1000 & !(word_1 %in% uninteresting | word_2 %in% uninteresting))
head(sort(greater1k,by="count",decreasing=T),10)
academic  <-  partition("BNC", text_derived_type = "academic")
spoken  <-  partition("BNC", text_derived_type = "spoken_conversation")
oneofthe_acad <- cooccurrences(academic,  query = "'one' 'of' 'the'", cqp = T, right = 1, left = 0) %>% subset(!tolower(word) %in% uninteresting)
oneofthe_spok <- cooccurrences(spoken,  query = "'one' 'of' 'the'", cqp = T, right = 1, left = 0) %>% subset(!tolower(word) %in% uninteresting)
common  <-  intersect(oneofthe_acad@stat[1:10,word],oneofthe_spok@stat[1:10,word])
distinctive  <-  setdiff(oneofthe_acad@stat[1:10,word],common)
head(oneofthe_spok@stat)
head(oneofthe_spok@stat)
head(oneofthe_acad@stat[word %in% distinctive,])
exit
library(ggplot2)
data(mpg)
ggplot(mtcars, aes(disp,mpg)) + geom_point() + geom_smooth(method="lm",se=F) + opts(title="la economía de la gasonlina como función del tamaño del motor")
help(opts)
??opts
library(ggplot2)
data(mpg)
ggplot(mtcars, aes(disp,mpg)) + geom_point() + geom_smooth(method="lm",se=F)# + opts(title="la economía de la gasolina como función del tamaño del motor")
library(ggplot2)
data(mpg)
ggplot(mtcars, aes(disp,mpg)) + geom_point() + geom_smooth(method="lm",se=F) + ggtitle("la economía de la gasolina como función del tamaño del motor")
# BNC> count FICTION by word %c > "| wc -l";
# 131476
# BNC> count NEWS by word %c  > "| wc -l";
# 152648
# BNC> [ word = ".+icles?" %c ] ;
# BNC> size Last ;
# 20854
# BNC> group Last match word > "icle-hits.txt";
# BNC> define $stopword < "not-instances-of-mini.txt" ;
# BNC> MINI1 = [ word="mini(-)?.+" %c & word != RE($stopword) %c] ;
# BNC> size MINI1
# 1840
# BNC> count MINI1 by word %c > "| wc -l";
# 510
# BNC> randomize 37;
# BNC> ICLE = [ word = ".+icles?" %c ] ;
# BNC> reduce ICLE to 1840 ;
# BNC> group ICLE match word > "icle1840.txt";
# DICKENS> PhrasalV = @[ pos="V.*" & lemma != "be" ] [ word="out" ] [ word != "that"];
# DICKENS> group PhrasalV target lemma cut 100 ;
# BROWN> NONPUNCT = [ pos != "(\.|\(|\)|\*|--|\,|:|``|''|')(-(HL|TL|NC)){0,2}" ] ;
# BROWN> count NONPUNCT by word %c ;
# BROWN> count NONPUNCT by word %c > "| egrep '^1[[:blank:]]' | wc -l" ;
# 22012
# BROWN> count NONPUNCT by word %c > "|  wc -l" ;
# 49804
# BROWN> count NONPUNCT by word %c > "| awk '{print $1,$2}' > brown-nonpunct.cnt" ;
# laptop% scp ugaMyID@corpus.uga.edu:brown-nonpunct.cnt .
# library(ggplot2)
# brown <- read.table("brown-nonpunct.cnt",header=F,colClasses=c("integer","character"),sep=" "))
# names(brown) <- c("attestations","word")
# quickplot(1:100,brown$attestations[1:100],main="Brown corpus",xlab="rank",ylab="attestations",log="xy",geom=c("point","smooth"),method="lm",se=F)
#> Sys.setenv("CORPUS_REGISTRY" = "/Volumes/cwb_registry/mac_registry") # or "R:/windows_registry" if you are running Windows
#> Sys.getenv("CORPUS_REGISTRY") # check that it was successfully set
#> library(polmineR)
#> corpus()
#> kwic("DICKENS","door-nail")
#> kwic("DICKENS",query="door-nail")
#> count("DICKENS",query="nail")
#> count("DICKENS",query="nails")
#> count("DICKENS",query='"nails?"',cqp=TRUE)
#> count("DICKENS",query=' [word="nails?"] ',cqp=T)
#> ail<-count("DICKENS",query=c("nail","nails"))
#> i  <- nail$query=="nails"
#> i
#> nail[i]
#> rsc  <-  corpus("RSC")
#> show_info(rsc)
#> s_attributes(rsc)
#> divers  <- dispersion("RSC",query='divers',s_attribute="text_year")
#> head(divers)
#> barplot(height = divers$count, names.arg = divers$text_year, las = 2)
# everything is NA
#> w_count <- rep(NA,times=size("WUTHERING"))
# until Healthcliff is mentioned
#> where_he_is_mentioned  <- cpos("WUTHERING","Heathcliff")[,1]
# set all of those corpus positions to the value 1
#> w_count[where_he_is_mentioned] <- 1
#Your plot may also appear a lot taller (or thicker) than the one seen here.
#> plot(w_count,main="Gráfica de dispersión de `Healthcliff` en Wuthering Heights",xlab="Duración de la Novela",ylab="Healthcliff",type="h",ylim=c(0,1),yaxt='n')
# everything is NA
#> w_count2 <- rep(NA,times=size("WUTHERING"))
# until Edgar is mentioned
#> where_edgar_is_mentioned  <- cpos("WUTHERING","Edgar")[,1]
# set all of those corpus positions to the value 1
#> w_count2[where_edgar_is_mentioned] <- 1
#Your plot may also appear a lot taller (or thicker) than the one seen here.
#> plot(w_count2,main="Gráfica de dispersión de `Edgar` en Wuthering Heights",xlab="Duración de la Novela",ylab="Edgar",type="h",ylim=c(0,1),yaxt='n')
#> count("BNC",query="breakfast")
#> bkf_by_text  <- dispersion("BNC","breakfast",s_attribute="text_id")
#> head(bkf_by_text)
#> texts_where_bkfast_is_mentioned  <- bkf_by_text[bkf_by_text$count > 0]
#> total_number_texts  <-  length(unique(bkf_by_text$text_id))
#> number_bkfast_texts  <- length(unique(texts_where_bkfast_is_mentioned$text_id))
#> (number_bkfast_texts/total_number_texts)*100
#[1] 25.58656
# lovely <- dispersion("BNC", query = "lovely", s_attribute = "text_author_sex")
# ace <- dispersion("BNC", query = "ace", s_attribute = "text_author_sex")
#> four_counts  <- c(lovely[text_author_sex=="male"]$count,ace[text_author_sex=="male"]$count,lovely[text_author_sex=="female"]$count,ace[text_author_sex=="female"]$count)
#> T <- matrix(four_counts,ncol=2)
# add names for the table's columns and rows
#> rownames(T) <- c("lovely", "ace")
#> colnames(T) <- c("male", "female")
#> T
#       male female
#lovely  751   1337
#ace      48     19
#> marginSums(T,1)
#lovely    ace
#  2088     67
#> marginSums(T,2)
#  male female
#   799   1356
#> prop.table(T)
#             male      female
#lovely 0.34849188 0.620417633
#ace    0.02227378 0.008816705
# must <- dispersion("BNC", query = "must", s_attribute = "text_text_type")
# needto <- dispersion("BNC", query = "'need' 'to'", s_attribute = "text_text_type")
articlechoice  <- read.csv(file="the_a(n).csv",header=T)
# articlechoice es ahora un data frame con columnas y filas que tienen los títulos indicados en el archivo (CSV)
articlechoice$Article_type  <- as.factor(articlechoice$Article_type)
articlechoice$Context_type  <- as.factor(articlechoice$Context_type)
def_by_cntx  <-  with(articlechoice,table(Context_type,Article_type))
def_by_cntx
definiteness  <- marginSums(def_by_cntx,2)
definiteness
definiteness[["a_indefinite"]] / sum(definiteness)
cntx  <-  marginSums(def_by_cntx,1)
cntx
cntx[["b_determined"]] / sum(cntx)
library(dplyr)
library(ggplot2)
library(tidyr)
data.frame(chisq = 0:7000 / 100) %>%
mutate(df_05 = dchisq(x = chisq, df = 5),
df_15 = dchisq(x = chisq, df = 15),
df_30 = dchisq(x = chisq, df = 30)) %>%
gather(key = "df", value = "density", -chisq) %>%
ggplot() +
geom_line(aes(x = chisq, y = density, color = df)) +
labs(title = "Chi-Square con varios Degrees of Freedom",
x = "Chi-cuadrado",
y = "Densidad")
chisq.test(def_by_cntx,correct=F)
result  <- chisq.test(def_by_cntx)
E  <- result$expected
O <- result$observed
sum((O - E)^2 / E)
pchisq(85.249,df=1,lower.tail=F)
#love_co <- cooccurrences("BNC", query = "love", left = 0, right=5, method="chisquare", verbose=T)
#love_df  <- as.data.frame(love_co)
#r1  <-  love_df[love_df$word=="love",]$count_partition
#c1  <-  love_df[love_df$word=="affair",]$count_partition
#n <- size("BNC") - 20160
# (r1*c1*5)/n
#[1] 2.767734
#affair  <- love_df[love_df$word=="affair",]$count_partition
#o11  <-  love_df[love_df$word=="affair",]$count_coi  # count of co-occurrences within window
#o21  <-  affair - o11
#o12  <-  love_co@size_coi - o11
#o22  <-  n - (o11+o21+o12) # grand total minus all the others
#O <- matrix(c(o11,o21,o12,o22),ncol=2)
#colnames(O)  <-  c("affair present", "affair not present")
#rownames(O) <- c("near love", "not near love")
#r1 <- marginSums(O,1)[[1]]
#r2 <- marginSums(O,1)[[2]]
#c1 <- marginSums(O,2)[[1]]
#c2 <- marginSums(O,2)[[2]]
#f <- function (numerator1,numerator2,denominator) { exp(log(numerator1)+log(numerator2)-log(denominator)) } # in log space to avoid overflow
#E <- matrix(c(f(r1,c1,n),f(r2,c1,n),f(r1,c2,n),f(r2,c2,n)),ncol=2)
#colnames(E)  <-  c("affair present", "affair not present")
#rownames(E) <- c("near love", "not near love")
#> E
#              affair present affair not present
#near love           2.767734           100797.2
#not near love    3076.232266        112032324.8
#> sum((O - E)^2 / E)
#[1] 11617.44
# last time
#love_chisq  <-  cooccurrences("BNC", query = "love", left = 0, right=5, method="chisquare")
#> as.data.table(love_chisq)[word=="affair"]
#     word word_id count_partition count_coi count_ref  exp_coi chisquare rank_chisquare
#1: affair    7668            3079       182      2897 2.767734  11617.44              1
# this time
#love_ll  <-  cooccurrences("BNC", query = "love", left = 0, right=5, method="ll")
#> head(love_ll,10)
#      word word_id count_partition count_coi count_ref     exp_coi     exp_ref       ll rank_ll
#1:    you      66          574132      2188    571944  516.091192  573615.909 3010.071       1
#2:     ''     165          752264      2347    749917  676.215268  751587.785 2531.337       2
#3:   love     876           20160       417     19743   18.121962   20141.878 1827.170       3
#4:   with      43          639450      1835    637615  574.805990  638875.194 1758.041       4
#5:    him     920          152878       818    152060  137.423082  152740.577 1564.793       5
#6:      .      22         4715138      6772   4708366 4238.469880 4710899.530 1348.064       6
#7:    her      53          287910      1019    286891  258.804273  287651.196 1280.476       7
#8:     me     395          129238       679    128559  116.172924  129121.827 1277.563       8
#9: affair    7668            3079       182      2897    2.767734    3076.232 1176.202       9
#10:    God    2104           20382       279     20103   18.321520   20363.678 1002.179      10
#> b <- cooccurrences("BNC","bachelor")
#> head(b,10)
#uninteresting  <- c("bachelor","spinster","``","''",punctuation,tm::stopwords("en"))
#bach <- cooccurrences("BNC", query = "bachelor", right = 5, left = 5) %>% subset(!tolower(word) %in% uninteresting)
#spin <- cooccurrences("BNC", query = "spinster", right = 5, left = 5) %>% subset(!tolower(word) %in% uninteresting)
#> library(ggplot2)
#>ggplot(bach@stat[1:14],aes(x=ll,y=reorder(word,-rank_ll))) + geom_point(color="blue") +
#    labs(title="\"bachelor\" in BNC",x="log-likelihood",y="collocate")
#>ggplot(spin@stat[1:14],aes(x=ll,y=reorder(word,-rank_ll))) + geom_point(color="red") +
#    labs(title="\"spinster\" in BNC",x="log-likelihood",y="collocate")
#>mypunctuation  <-  c(punctuation,"``","''")
#>trigrams  <-  ngrams("BNC",n=3)
#>nopunct_greater10k  <-  subset(trigrams, count > 10000 & !(word_1 %in% mypunctuation | word_2 %in% mypunctuation | word_3 %in% mypunctuation))
#>bnc_all  <- sort(nopunct_greater10k,by="count",decreasing=T)
#>academic  <-  partition("BNC", text_derived_type = "academic")
#>spoken  <-  partition("BNC", text_derived_type = "spoken_conversation")
#>oneofthe_acad <- cooccurrences(academic,  query = "'one' 'of' 'the'", cqp = T, right = 1, left = 0) %>% subset(!tolower(word) %in% uninteresting)
#>oneofthe_spok <- cooccurrences(spoken,  query = "'one' 'of' 'the'", cqp = T, right = 1, left = 0) %>% subset(!tolower(word) %in% uninteresting)
# solo consideramos los primeros 10 colocados
#>common  <-  intersect(oneofthe_acad@stat[1:10,word],oneofthe_spok@stat[1:10,word])
#>distinctive  <-  setdiff(oneofthe_acad@stat[1:10,word],common)
#>head(oneofthe_spok@stat)
#>head(oneofthe_acad@stat[word %in% distinctive,])
library(ggplot2)
data(mpg)
ggplot(mtcars, aes(disp,mpg)) + geom_point() + geom_smooth(method="lm",se=F) + ggtitle("la economía de la gasolina como función del tamaño del motor")
coefficients(m)
m <- lm(hwy~displ,data=mpg)
coefficients(m)
slope <- unname(coef(m)[2])
intercept <- unname(coef(m)[1])
slope*5.3 + intercept
install.packages("languageR")
library(languageR)
data(dative)
library(languageR)
data(dative)
head(dative)
dative_mdl <- glm(RealizationOfRecipient ~ AnimacyOfRec, data=dative, family="binomial")
summary(dative_mdl)
table(dative$RealizationOfRecipient)
# extraer los betas del "fitted model"
intercept <- unname(dative_mdl$coefficients[1])
slope <- unname(dative_mdl$coefficients[2])
# extraer los betas del "fitted model"
intercept <- unname(dative_mdl$coefficients[1])
slope <- unname(dative_mdl$coefficients[2])
# extraer los betas del "fitted model"
intercept <- unname(dative_mdl$coefficients[1])
slope <- unname(dative_mdl$coefficients[2])
plogis(intercept + slope*0) # animate
plogis(intercept + slope*1) # inanimate
# extraer los betas del "fitted model"
intercept <- unname(dative_mdl$coefficients[1])
slope <- unname(dative_mdl$coefficients[2])
plogis(intercept + slope*0) # animate
plogis(intercept + slope*1) # inanimate
install.packages("readxl")
library(tidyverse)
library(readxl)
# abrir los datos de Brezina sección 6.5
rv  <- read_excel("mixed_effect_intensifiers.xlsx") %>% mutate_if(is.character,compose(as.factor,trimws))
library(tidyverse)
library(readxl)
# abrir los datos de Brezina sección 6.5
rv  <- read_excel("mixed_effect_intensifiers.xlsx") %>% mutate_if(is.character,compose(as.factor,trimws))
library(lme4)
install.packages("lme4")
library(lme4)
ml <- glmer(Outcome ~ Gender + Class + Age + Syntax + (1|Speaker), data=rv, family="binomial")
summary(ml,corr=F)
head(select(coef(m1)$Speaker,"(Intercept)"))
head(select(coef(ml)$Speaker,"(Intercept)"))
m0  <- glm(Outcome ~ Gender + Class + Age + Syntax, data=rv, family="binomial")
summary(m0)
compl <- read.table("compl_spoken2.csv", header=T, sep=",", dec=".", stringsAsFactors=T)
library(lme4)
maximal_model <- glmer(label_verbose ~ verbmorph +
matrix_subject_type_3 +
log(emb_cl_length) +
log(interv_material_macl_embcl + 1) +
horror_aequi +
log(ehms_etc_narrow + 1) +
ttrpassage +
adv_beginning +
adv_afterend +
matrix_negation +
matrix_auxiliary +
complement_subject +
I_THINK_alert +
alpha_persistence_50 +
verbid +
morphid +
(1|speaker) + (1|verb) + (1|county) + (1|text),
data=compl,
family="binomial",
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e))
library(lme4)
maximal_model <- glmer(label_verbose ~ verbmorph +
matrix_subject_type_3 +
log(emb_cl_length) +
log(interv_material_macl_embcl + 1) +
horror_aequi +
log(ehms_etc_narrow + 1) +
ttrpassage +
adv_beginning +
adv_afterend +
matrix_negation +
matrix_auxiliary +
complement_subject +
I_THINK_alert +
alpha_persistence_50 +
verbid +
morphid +
(1|speaker) + (1|verb) + (1|county) + (1|text),
data=compl,
family="binomial",
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5))
))
library(lme4)
maximal_model <- glmer(label_verbose ~ verbmorph +
matrix_subject_type_3 +
log(emb_cl_length) +
log(interv_material_macl_embcl + 1) +
horror_aequi +
log(ehms_etc_narrow + 1) +
ttrpassage +
adv_beginning +
adv_afterend +
matrix_negation +
matrix_auxiliary +
complement_subject +
I_THINK_alert +
alpha_persistence_50 +
verbid +
morphid +
(1|speaker) + (1|verb) + (1|county) + (1|text),
data=compl,
family="binomial",
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)
))
car::vif(maximal_model)
library(car)
install.packages("car")
library(car)
car::vif(maximal_model)
no_verb <- update(maximal_model, . ~ . -verbmorph)
noverbmorphdeviance  <- -2 * logLik(no_verb) + 2 * logLik(maximal_model)
pchisq(as.numeric(noverbmorphdeviance), df=3, lower.tail=F)  # 4 - 1 = 3 degrees of freedom
anova(no_verb, maximal_model, test="Chisq")
drop1(maximal, test="Chisq")
no_county <- update(maximal_model, . ~ . -(1|county))
anova(maximal_model, no_county, test="Chisq")
drop1(maximal, test="Chisq")
drop1(maximal_model, test="Chisq")
summary(optimal_model)
optimal_model <- glmer(label_verbose ~
verbmorph +
matrix_subject_type_3 +
horror_aequi +
adv_afterend +
matrix_auxiliary +
complement_subject +
I_THINK_alert +
alpha_persistence_50 +
log(emb_cl_length) +
log(ehms_etc_narrow + 1) +
(1 |verb) +
(1 |speaker) +
(1 |county) +
(1 |text),
data=compl,
family="binomial",
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
summary(optimal_model)
intercept  <- unname(fixef(optimal_model)[1])
thirdpersoninanimate <- unname(fixef(optimal_model)[6])
clauselength <- unname(fixef(optimal_model)[14])
disfluency  <-  unname(fixef(optimal_model)[15])
plogis(intercept + thirdpersoninanimate*0 + clauselength*mean(log(compl$emb_cl_length)) + disfluency*mean(log(compl$ehms_etc_narrow +1)))
plogis(intercept + thirdpersoninanimate*1 + clauselength*mean(log(compl$emb_cl_length)) + disfluency*mean(log(compl$ehms_etc_narrow +1)))
